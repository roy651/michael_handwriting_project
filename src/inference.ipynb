{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ef6ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 1: Import Libraries and Set Up Environment ---\n",
    "\"\"\"\n",
    "# Handwritten Character Recognition: Inference Notebook\n",
    "\n",
    "This notebook demonstrates how to use trained handwritten character recognition models for inference.\n",
    "It covers loading models, performing single and batch inference, analyzing results, and visualizing predictions.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import json\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "\n",
    "# Import utility modules\n",
    "from src.models_util import get_model, get_model_info\n",
    "from src.inference_utils import prepare_single_image, predict_single_image, predict_batch_images\n",
    "from src.inference_utils import extract_characters_from_image, create_visualization_grid\n",
    "from src.inference_utils import get_top_k_predictions, benchmark_inference_speed\n",
    "\n",
    "# For reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Device configuration\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create directories for saving results\n",
    "os.makedirs(\"inference_results\", exist_ok=True)\n",
    "os.makedirs(\"inference_results/single\", exist_ok=True)\n",
    "os.makedirs(\"inference_results/batch\", exist_ok=True)\n",
    "os.makedirs(\"inference_results/text\", exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2bbdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 2: Model Loading Functions ---\n",
    "\"\"\"\n",
    "## Model Loading Functions\n",
    "\n",
    "These functions handle loading trained models from checkpoints.\n",
    "They include options for different model architectures and configurations.\n",
    "\"\"\"\n",
    "\n",
    "def load_model_checkpoint(checkpoint_path, model_name, num_classes, device=device):\n",
    "    \"\"\"\n",
    "    Load a model from a checkpoint file.\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_path: Path to the checkpoint file\n",
    "        model_name: Name of the model architecture\n",
    "        num_classes: Number of output classes\n",
    "        device: Device to load the model on\n",
    "        \n",
    "    Returns:\n",
    "        torch.nn.Module: Loaded model\n",
    "    \"\"\"\n",
    "    print(f\"Loading model checkpoint from: {checkpoint_path}\")\n",
    "    \n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        print(f\"ERROR: Checkpoint file '{checkpoint_path}' not found\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Initialize the model architecture\n",
    "        model = get_model(model_name, num_classes, device, pretrained=False)\n",
    "        \n",
    "        # Load the checkpoint\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        \n",
    "        # Extract state dict\n",
    "        if 'model_state_dict' in checkpoint:\n",
    "            state_dict = checkpoint['model_state_dict']\n",
    "        else:\n",
    "            # Handle case where checkpoint is just the state dict\n",
    "            state_dict = checkpoint\n",
    "        \n",
    "        # Load state dict into model\n",
    "        model.load_state_dict(state_dict)\n",
    "        \n",
    "        # Set model to evaluation mode\n",
    "        model.eval()\n",
    "        \n",
    "        print(f\"Model loaded successfully with {sum(p.numel() for p in model.parameters())} parameters\")\n",
    "        \n",
    "        # Extract metadata if available\n",
    "        metadata = {}\n",
    "        for key in ['epoch', 'accuracy', 'val_acc', 'loss']:\n",
    "            if key in checkpoint:\n",
    "                metadata[key] = checkpoint[key]\n",
    "        \n",
    "        if metadata:\n",
    "            print(f\"Checkpoint metadata:\")\n",
    "            for key, value in metadata.items():\n",
    "                print(f\"  {key}: {value}\")\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model checkpoint: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "def load_class_names(class_names_path):\n",
    "    \"\"\"\n",
    "    Load class names from a text file.\n",
    "    \n",
    "    Args:\n",
    "        class_names_path: Path to the class names file\n",
    "        \n",
    "    Returns:\n",
    "        list: List of class names\n",
    "    \"\"\"\n",
    "    print(f\"Loading class names from: {class_names_path}\")\n",
    "    \n",
    "    if not os.path.exists(class_names_path):\n",
    "        print(f\"ERROR: Class names file '{class_names_path}' not found\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        with open(class_names_path, 'r') as f:\n",
    "            class_names = [line.strip() for line in f if line.strip()]\n",
    "        \n",
    "        print(f\"Loaded {len(class_names)} class names\")\n",
    "        return class_names\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading class names: {e}\")\n",
    "        return None\n",
    "\n",
    "def find_available_models(model_checkpoints_dir=\"model_checkpoints\"):\n",
    "    \"\"\"\n",
    "    Find available trained models in the checkpoints directory.\n",
    "    \n",
    "    Args:\n",
    "        model_checkpoints_dir: Directory containing model checkpoints\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary of available models\n",
    "    \"\"\"\n",
    "    print(f\"Searching for available models in: {model_checkpoints_dir}\")\n",
    "    \n",
    "    if not os.path.exists(model_checkpoints_dir):\n",
    "        print(f\"ERROR: Model checkpoints directory '{model_checkpoints_dir}' not found\")\n",
    "        return {}\n",
    "    \n",
    "    available_models = {}\n",
    "    \n",
    "    # List subdirectories (each should be a model type)\n",
    "    model_dirs = [d for d in os.listdir(model_checkpoints_dir) \n",
    "                if os.path.isdir(os.path.join(model_checkpoints_dir, d))]\n",
    "    \n",
    "    for model_dir in model_dirs:\n",
    "        model_path = os.path.join(model_checkpoints_dir, model_dir)\n",
    "        \n",
    "        # Check for model checkpoints\n",
    "        checkpoint_files = []\n",
    "        for ext in ['*.pth', '*.pt']:\n",
    "            checkpoint_files.extend(glob(os.path.join(model_path, ext)))\n",
    "        \n",
    "        if checkpoint_files:\n",
    "            # Check for class_names.txt\n",
    "            class_names_path = os.path.join(model_path, 'class_names.txt')\n",
    "            has_class_names = os.path.exists(class_names_path)\n",
    "            \n",
    "            # Check for model_info.txt\n",
    "            model_info_path = os.path.join(model_path, 'model_info.txt')\n",
    "            has_model_info = os.path.exists(model_info_path)\n",
    "            \n",
    "            available_models[model_dir] = {\n",
    "                'checkpoint_files': sorted(checkpoint_files),\n",
    "                'class_names_path': class_names_path if has_class_names else None,\n",
    "                'model_info_path': model_info_path if has_model_info else None,\n",
    "                'has_class_names': has_class_names,\n",
    "                'has_model_info': has_model_info\n",
    "            }\n",
    "    \n",
    "    if available_models:\n",
    "        print(f\"Found {len(available_models)} available models:\")\n",
    "        for model_name, info in available_models.items():\n",
    "            print(f\"  - {model_name}:\")\n",
    "            print(f\"    - Checkpoints: {len(info['checkpoint_files'])}\")\n",
    "            print(f\"    - Has class names: {info['has_class_names']}\")\n",
    "            print(f\"    - Has model info: {info['has_model_info']}\")\n",
    "    else:\n",
    "        print(\"No trained models found.\")\n",
    "    \n",
    "    return available_models\n",
    "\n",
    "def load_inference_model(model_name, checkpoint_type=\"best\", model_checkpoints_dir=\"model_checkpoints\"):\n",
    "    \"\"\"\n",
    "    Load a model for inference.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name of the model to load\n",
    "        checkpoint_type: Type of checkpoint to load ('best', 'final', or specific path)\n",
    "        model_checkpoints_dir: Directory containing model checkpoints\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (model, class_names)\n",
    "    \"\"\"\n",
    "    print(f\"Loading model '{model_name}' for inference...\")\n",
    "    \n",
    "    # Find available models\n",
    "    available_models = find_available_models(model_checkpoints_dir)\n",
    "    \n",
    "    if model_name not in available_models:\n",
    "        print(f\"ERROR: Model '{model_name}' not found in available models\")\n",
    "        return None, None\n",
    "    \n",
    "    model_info = available_models[model_name]\n",
    "    \n",
    "    # Load class names\n",
    "    if not model_info['has_class_names']:\n",
    "        print(f\"WARNING: No class_names.txt found for model '{model_name}'\")\n",
    "        print(\"Will use default class names (0-9, A-Z, a-z)\")\n",
    "        class_names = [str(i) for i in range(10)] + \\\n",
    "                     [chr(i) for i in range(65, 91)] + \\\n",
    "                     [chr(i) for i in range(97, 123)]\n",
    "    else:\n",
    "        class_names = load_class_names(model_info['class_names_path'])\n",
    "        \n",
    "    if class_names is None:\n",
    "        print(\"ERROR: Failed to load class names\")\n",
    "        return None, None\n",
    "    \n",
    "    num_classes = len(class_names)\n",
    "    \n",
    "    # Determine checkpoint path\n",
    "    checkpoint_path = None\n",
    "    \n",
    "    if checkpoint_type == \"best\":\n",
    "        # Look for best_model.pth or similar\n",
    "        best_paths = [cp for cp in model_info['checkpoint_files'] if 'best' in os.path.basename(cp).lower()]\n",
    "        if best_paths:\n",
    "            checkpoint_path = best_paths[0]\n",
    "        else:\n",
    "            print(\"WARNING: No 'best' checkpoint found, falling back to first available checkpoint\")\n",
    "            checkpoint_path = model_info['checkpoint_files'][0]\n",
    "    \n",
    "    elif checkpoint_type == \"final\":\n",
    "        # Look for final_model.pth or similar\n",
    "        final_paths = [cp for cp in model_info['checkpoint_files'] if 'final' in os.path.basename(cp).lower()]\n",
    "        if final_paths:\n",
    "            checkpoint_path = final_paths[0]\n",
    "        else:\n",
    "            print(\"WARNING: No 'final' checkpoint found, falling back to first available checkpoint\")\n",
    "            checkpoint_path = model_info['checkpoint_files'][0]\n",
    "    \n",
    "    elif os.path.exists(checkpoint_type):\n",
    "        # Use the provided path directly\n",
    "        checkpoint_path = checkpoint_type\n",
    "    \n",
    "    else:\n",
    "        print(f\"ERROR: Invalid checkpoint type '{checkpoint_type}'\")\n",
    "        return None, None\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model_checkpoint(checkpoint_path, model_name, num_classes, device)\n",
    "    \n",
    "    if model is None:\n",
    "        print(\"ERROR: Failed to load model\")\n",
    "        return None, None\n",
    "    \n",
    "    print(f\"Successfully loaded model '{model_name}' with {num_classes} classes\")\n",
    "    return model, class_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf74351f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 3: Single Image Inference ---\n",
    "\"\"\"\n",
    "## Single Image Inference\n",
    "\n",
    "Perform inference on a single image and visualize the results.\n",
    "This section includes functions for loading images, preprocessing them, and getting predictions.\n",
    "\"\"\"\n",
    "\n",
    "def infer_single_image(model, class_names, image_path, save_dir=\"inference_results/single\"):\n",
    "    \"\"\"\n",
    "    Perform inference on a single image and visualize the results.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        class_names: List of class names\n",
    "        image_path: Path to the input image\n",
    "        save_dir: Directory to save the results\n",
    "        \n",
    "    Returns:\n",
    "        dict: Prediction results\n",
    "    \"\"\"\n",
    "    print(f\"Running inference on image: {image_path}\")\n",
    "    \n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"ERROR: Image file '{image_path}' not found\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Predict using the utility function\n",
    "        result = predict_single_image(\n",
    "            model=model,\n",
    "            image_path=image_path,\n",
    "            class_names=class_names,\n",
    "            device=device,\n",
    "            normalization_type='imagenet',\n",
    "            return_probabilities=True\n",
    "        )\n",
    "        \n",
    "        # Display the prediction\n",
    "        img = Image.open(image_path)\n",
    "        \n",
    "        # Create visualization\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Original image\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(\"Input Image\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Prediction results\n",
    "        plt.subplot(1, 2, 2)\n",
    "        \n",
    "        # Get top 5 predictions\n",
    "        probs = result['class_probabilities']\n",
    "        top_k = 5\n",
    "        \n",
    "        # Sort probabilities and get top k\n",
    "        sorted_probs = sorted(probs.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "        \n",
    "        classes = [cls for cls, _ in sorted_probs]\n",
    "        values = [val for _, val in sorted_probs]\n",
    "        \n",
    "        plt.barh(range(len(classes)), values, color='skyblue')\n",
    "        plt.yticks(range(len(classes)), classes)\n",
    "        plt.xlim(0, 1)\n",
    "        plt.xlabel(\"Confidence\")\n",
    "        plt.title(f\"Prediction: {result['predicted_class']} ({result['confidence']:.2%})\")\n",
    "        plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # Add values on the bars\n",
    "        for i, v in enumerate(values):\n",
    "            plt.text(v + 0.01, i, f\"{v:.2%}\", va='center')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the visualization\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        basename = os.path.basename(image_path)\n",
    "        save_path = os.path.join(save_dir, f\"prediction_{basename}\")\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        print(f\"Prediction saved to {save_path}\")\n",
    "        plt.show()\n",
    "        \n",
    "        # Print the prediction\n",
    "        print(f\"Prediction: {result['predicted_class']} with confidence {result['confidence']:.2%}\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during inference: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "def visualize_activation_map(model, image_path, class_names, save_dir=\"inference_results/single\"):\n",
    "    \"\"\"\n",
    "    Visualize the activation map for a single image.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model (must support hooks for grad-CAM)\n",
    "        image_path: Path to the input image\n",
    "        class_names: List of class names\n",
    "        save_dir: Directory to save the results\n",
    "        \n",
    "    Returns:\n",
    "        dict: Visualization results\n",
    "    \"\"\"\n",
    "    print(f\"Generating activation map for image: {image_path}\")\n",
    "    \n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"ERROR: Image file '{image_path}' not found\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Load and preprocess the image\n",
    "        img = Image.open(image_path).convert('L')\n",
    "        img_tensor = prepare_single_image(image_path, normalization_type='imagenet', device=device)\n",
    "        \n",
    "        # Check if the model has features attribute (necessary for grad-CAM)\n",
    "        if not hasattr(model, 'features'):\n",
    "            print(\"WARNING: Model does not have 'features' attribute, cannot generate activation map\")\n",
    "            return None\n",
    "        \n",
    "        # Get the prediction\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = model(img_tensor)\n",
    "            probabilities = F.softmax(output, dim=1)\n",
    "            confidence, predicted_idx = torch.max(probabilities, 1)\n",
    "            predicted_class = class_names[predicted_idx.item()]\n",
    "        \n",
    "        # Generate activation map using grad-CAM\n",
    "        # We'll use the last convolutional layer in the features\n",
    "        target_layer = None\n",
    "        for module in reversed(list(model.features)):\n",
    "            if isinstance(module, torch.nn.Conv2d):\n",
    "                target_layer = module\n",
    "                break\n",
    "        \n",
    "        if target_layer is None:\n",
    "            print(\"WARNING: Could not find a convolutional layer in the model\")\n",
    "            return None\n",
    "        \n",
    "        # Set up hooks\n",
    "        feature_maps = None\n",
    "        gradients = None\n",
    "        \n",
    "        def save_feature_maps(module, input, output):\n",
    "            nonlocal feature_maps\n",
    "            feature_maps = output.detach()\n",
    "        \n",
    "        def save_gradients(module, grad_input, grad_output):\n",
    "            nonlocal gradients\n",
    "            gradients = grad_output[0].detach()\n",
    "        \n",
    "        # Register hooks\n",
    "        handle_forward = target_layer.register_forward_hook(save_feature_maps)\n",
    "        handle_backward = target_layer.register_backward_hook(save_gradients)\n",
    "        \n",
    "        # Forward pass with gradients\n",
    "        model.zero_grad()\n",
    "        output = model(img_tensor)\n",
    "        \n",
    "        # Get the gradient of the output with respect to the predicted class\n",
    "        one_hot = torch.zeros_like(output)\n",
    "        one_hot[0, predicted_idx.item()] = 1\n",
    "        \n",
    "        output.backward(gradient=one_hot)\n",
    "        \n",
    "        # Remove hooks\n",
    "        handle_forward.remove()\n",
    "        handle_backward.remove()\n",
    "        \n",
    "        # Calculate the weight of each feature map\n",
    "        weights = torch.mean(gradients, dim=(2, 3))\n",
    "        \n",
    "        # Generate the class activation map\n",
    "        batch_size, num_channels, height, width = feature_maps.size()\n",
    "        cam = torch.zeros(height, width, dtype=torch.float32, device=device)\n",
    "        \n",
    "        for i, w in enumerate(weights[0]):\n",
    "            cam += w * feature_maps[0, i]\n",
    "        \n",
    "        # Normalize the CAM\n",
    "        cam = F.relu(cam)\n",
    "        cam = cam - torch.min(cam)\n",
    "        cam = cam / (torch.max(cam) + 1e-10)\n",
    "        \n",
    "        # Resize to match the original image\n",
    "        cam = cam.cpu().numpy()\n",
    "        cam = cv2.resize(cam, (img.width, img.height))\n",
    "        \n",
    "        # Convert image to numpy\n",
    "        img_np = np.array(img)\n",
    "        \n",
    "        # Create heatmap\n",
    "        heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
    "        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Combine original image and heatmap\n",
    "        img_rgb = cv2.cvtColor(img_np, cv2.COLOR_GRAY2RGB)\n",
    "        superimposed = cv2.addWeighted(img_rgb, 0.6, heatmap, 0.4, 0)\n",
    "        \n",
    "        # Visualize\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(\"Original Image\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(cam, cmap='jet')\n",
    "        plt.title(\"Activation Map\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(superimposed)\n",
    "        plt.title(f\"Prediction: {predicted_class} ({confidence.item():.2%})\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the visualization\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        basename = os.path.basename(image_path)\n",
    "        save_path = os.path.join(save_dir, f\"activation_{basename}\")\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        print(f\"Activation map saved to {save_path}\")\n",
    "        plt.show()\n",
    "        \n",
    "        return {\n",
    "            'predicted_class': predicted_class,\n",
    "            'confidence': confidence.item(),\n",
    "            'cam': cam,\n",
    "            'superimposed': superimposed\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating activation map: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57062b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 4: Batch Inference ---\n",
    "\"\"\"\n",
    "## Batch Inference\n",
    "\n",
    "Process multiple images in batch mode for efficient inference.\n",
    "This section includes functions for folder processing and result aggregation.\n",
    "\"\"\"\n",
    "\n",
    "def infer_batch_images(model, class_names, image_folder, save_dir=\"inference_results/batch\", \n",
    "                     batch_size=16, visualize=True):\n",
    "    \"\"\"\n",
    "    Perform inference on multiple images in a folder.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        class_names: List of class names\n",
    "        image_folder: Path to the folder containing images\n",
    "        save_dir: Directory to save the results\n",
    "        batch_size: Batch size for processing\n",
    "        visualize: Whether to visualize the results\n",
    "        \n",
    "    Returns:\n",
    "        list: Prediction results for all images\n",
    "    \"\"\"\n",
    "    print(f\"Running batch inference on images in: {image_folder}\")\n",
    "    \n",
    "    if not os.path.exists(image_folder):\n",
    "        print(f\"ERROR: Image folder '{image_folder}' not found\")\n",
    "        return None\n",
    "    \n",
    "    # Find all image files\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff', '.gif']\n",
    "    image_paths = []\n",
    "    \n",
    "    for ext in image_extensions:\n",
    "        image_paths.extend(glob(os.path.join(image_folder, f\"*{ext}\")))\n",
    "        image_paths.extend(glob(os.path.join(image_folder, f\"*{ext.upper()}\")))\n",
    "    \n",
    "    if not image_paths:\n",
    "        print(f\"ERROR: No image files found in '{image_folder}'\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Found {len(image_paths)} images for batch inference\")\n",
    "    \n",
    "    try:\n",
    "        # Predict using the utility function\n",
    "        results = predict_batch_images(\n",
    "            model=model,\n",
    "            image_paths=image_paths,\n",
    "            class_names=class_names,\n",
    "            device=device,\n",
    "            normalization_type='imagenet',\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "        \n",
    "        # Create a summary of results\n",
    "        summary = {\n",
    "            'total_images': len(image_paths),\n",
    "            'predicted_classes': {},\n",
    "            'confidence_stats': {\n",
    "                'min': min(r['confidence'] for r in results),\n",
    "                'max': max(r['confidence'] for r in results),\n",
    "                'avg': sum(r['confidence'] for r in results) / len(results)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Count predicted classes\n",
    "        for result in results:\n",
    "            pred_class = result['predicted_class']\n",
    "            if pred_class in summary['predicted_classes']:\n",
    "                summary['predicted_classes'][pred_class] += 1\n",
    "            else:\n",
    "                summary['predicted_classes'][pred_class] = 1\n",
    "        \n",
    "        # Sort class counts in descending order\n",
    "        summary['predicted_classes'] = dict(sorted(\n",
    "            summary['predicted_classes'].items(), \n",
    "            key=lambda x: x[1], \n",
    "            reverse=True\n",
    "        ))\n",
    "        \n",
    "        # Save results to JSON\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        results_file = os.path.join(save_dir, 'batch_results.json')\n",
    "        \n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump({\n",
    "                'summary': summary,\n",
    "                'predictions': results\n",
    "            }, f, indent=2)\n",
    "        \n",
    "        print(f\"Batch results saved to {results_file}\")\n",
    "        \n",
    "        # Visualize results if requested\n",
    "        if visualize:\n",
    "            # Class distribution\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            \n",
    "            classes = list(summary['predicted_classes'].keys())\n",
    "            counts = list(summary['predicted_classes'].values())\n",
    "            \n",
    "            # Limit to top 20 classes if there are too many\n",
    "            if len(classes) > 20:\n",
    "                classes = classes[:20]\n",
    "                counts = counts[:20]\n",
    "                plt.title(\"Top 20 Predicted Classes\")\n",
    "            else:\n",
    "                plt.title(\"Predicted Class Distribution\")\n",
    "            \n",
    "            plt.bar(classes, counts, color='skyblue')\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.ylabel(\"Count\")\n",
    "            plt.xlabel(\"Class\")\n",
    "            plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save the visualization\n",
    "            class_dist_file = os.path.join(save_dir, 'class_distribution.png')\n",
    "            plt.savefig(class_dist_file, dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "            # Confidence distribution\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            \n",
    "            confidences = [r['confidence'] for r in results]\n",
    "            plt.hist(confidences, bins=20, color='skyblue', edgecolor='black')\n",
    "            plt.axvline(x=summary['confidence_stats']['avg'], color='red', linestyle='--', \n",
    "                      label=f\"Avg: {summary['confidence_stats']['avg']:.2%}\")\n",
    "            plt.xlabel(\"Confidence\")\n",
    "            plt.ylabel(\"Count\")\n",
    "            plt.title(\"Confidence Distribution\")\n",
    "            plt.grid(linestyle='--', alpha=0.7)\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save the visualization\n",
    "            conf_dist_file = os.path.join(save_dir, 'confidence_distribution.png')\n",
    "            plt.savefig(conf_dist_file, dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "            # Sample predictions\n",
    "            sample_count = min(5, len(results))\n",
    "            sample_indices = random.sample(range(len(results)), sample_count)\n",
    "            \n",
    "            plt.figure(figsize=(15, 3 * sample_count))\n",
    "            \n",
    "            for i, idx in enumerate(sample_indices):\n",
    "                result = results[idx]\n",
    "                img_path = result['image_path']\n",
    "                img = Image.open(img_path)\n",
    "                \n",
    "                plt.subplot(sample_count, 2, i*2 + 1)\n",
    "                plt.imshow(img)\n",
    "                plt.title(f\"Sample {i+1}\")\n",
    "                plt.axis('off')\n",
    "                \n",
    "                plt.subplot(sample_count, 2, i*2 + 2)\n",
    "                plt.text(0.5, 0.5, \n",
    "                       f\"Predicted: {result['predicted_class']}\\nConfidence: {result['confidence']:.2%}\", \n",
    "                       ha='center', va='center', fontsize=12)\n",
    "                plt.axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save the visualization\n",
    "            samples_file = os.path.join(save_dir, 'sample_predictions.png')\n",
    "            plt.savefig(samples_file, dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during batch inference: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "def analyze_batch_results(results_file, save_dir=\"inference_results/batch\"):\n",
    "    \"\"\"\n",
    "    Analyze the results of batch inference.\n",
    "    \n",
    "    Args:\n",
    "        results_file: Path to the JSON file containing batch results\n",
    "        save_dir: Directory to save the analysis results\n",
    "        \n",
    "    Returns:\n",
    "        dict: Analysis results\n",
    "    \"\"\"\n",
    "    print(f\"Analyzing batch inference results from: {results_file}\")\n",
    "    \n",
    "    if not os.path.exists(results_file):\n",
    "        print(f\"ERROR: Results file '{results_file}' not found\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Load results\n",
    "        with open(results_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        summary = data['summary']\n",
    "        predictions = data['predictions']\n",
    "        \n",
    "        print(f\"Loaded results for {summary['total_images']} images\")\n",
    "        \n",
    "        # Additional analysis\n",
    "        analysis = {\n",
    "            'total_images': summary['total_images'],\n",
    "            'class_distribution': summary['predicted_classes'],\n",
    "            'confidence_stats': summary['confidence_stats'],\n",
    "            'high_confidence': [],\n",
    "            'low_confidence': [],\n",
    "            'confidence_by_class': {}\n",
    "        }\n",
    "        \n",
    "        # Find high and low confidence predictions\n",
    "        confidence_threshold_high = 0.9\n",
    "        confidence_threshold_low = 0.5\n",
    "        \n",
    "        for pred in predictions:\n",
    "            # High confidence\n",
    "            if pred['confidence'] >= confidence_threshold_high:\n",
    "                analysis['high_confidence'].append(pred)\n",
    "            \n",
    "            # Low confidence\n",
    "            if pred['confidence'] <= confidence_threshold_low:\n",
    "                analysis['low_confidence'].append(pred)\n",
    "            \n",
    "            # Confidence by class\n",
    "            pred_class = pred['predicted_class']\n",
    "            if pred_class not in analysis['confidence_by_class']:\n",
    "                analysis['confidence_by_class'][pred_class] = []\n",
    "            \n",
    "            analysis['confidence_by_class'][pred_class].append(pred['confidence'])\n",
    "        \n",
    "        # Calculate average confidence by class\n",
    "        analysis['avg_confidence_by_class'] = {}\n",
    "        for cls, confs in analysis['confidence_by_class'].items():\n",
    "            analysis['avg_confidence_by_class'][cls] = sum(confs) / len(confs)\n",
    "        \n",
    "        # Sort classes by average confidence\n",
    "        analysis['avg_confidence_by_class'] = dict(sorted(\n",
    "            analysis['avg_confidence_by_class'].items(),\n",
    "            key=lambda x: x[1],\n",
    "            reverse=True\n",
    "        ))\n",
    "        \n",
    "        # Create visualizations\n",
    "        # 1. Average confidence by class\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        classes = list(analysis['avg_confidence_by_class'].keys())\n",
    "        avg_confs = list(analysis['avg_confidence_by_class'].values())\n",
    "        \n",
    "        # Limit to top 20 and bottom 10 classes if there are too many\n",
    "        if len(classes) > 30:\n",
    "            top_classes = classes[:20]\n",
    "            top_confs = avg_confs[:20]\n",
    "            \n",
    "            bottom_classes = classes[-10:]\n",
    "            bottom_confs = avg_confs[-10:]\n",
    "            \n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.bar(top_classes, top_confs, color='green')\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.ylabel(\"Average Confidence\")\n",
    "            plt.title(\"Top 20 Classes by Confidence\")\n",
    "            plt.ylim(0, 1)\n",
    "            plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "            \n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.bar(bottom_classes, bottom_confs, color='red')\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.ylabel(\"Average Confidence\")\n",
    "            plt.title(\"Bottom 10 Classes by Confidence\")\n",
    "            plt.ylim(0, 1)\n",
    "            plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        else:\n",
    "            plt.bar(classes, avg_confs, color='skyblue')\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.ylabel(\"Average Confidence\")\n",
    "            plt.title(\"Average Confidence by Class\")\n",
    "            plt.ylim(0, 1)\n",
    "            plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the visualization\n",
    "        avg_conf_file = os.path.join(save_dir, 'avg_confidence_by_class.png')\n",
    "        plt.savefig(avg_conf_file, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        # 2. Sample high and low confidence predictions\n",
    "        sample_high = min(3, len(analysis['high_confidence']))\n",
    "        sample_low = min(3, len(analysis['low_confidence']))\n",
    "        \n",
    "        if sample_high > 0 or sample_low > 0:\n",
    "            plt.figure(figsize=(15, 3 * (sample_high + sample_low)))\n",
    "            \n",
    "            # High confidence samples\n",
    "            for i in range(sample_high):\n",
    "                pred = analysis['high_confidence'][i]\n",
    "                img_path = pred['image_path']\n",
    "                img = Image.open(img_path)\n",
    "                \n",
    "                plt.subplot(sample_high + sample_low, 2, i*2 + 1)\n",
    "                plt.imshow(img)\n",
    "                plt.title(f\"High Confidence Sample {i+1}\")\n",
    "                plt.axis('off')\n",
    "                \n",
    "                plt.subplot(sample_high + sample_low, 2, i*2 + 2)\n",
    "                plt.text(0.5, 0.5,\n",
    "                       f\"Predicted: {pred['predicted_class']}\\nConfidence: {pred['confidence']:.2%}\",\n",
    "                       ha='center', va='center', fontsize=12)\n",
    "                plt.axis('off')\n",
    "            \n",
    "            # Low confidence samples\n",
    "            for i in range(sample_low):\n",
    "                pred = analysis['low_confidence'][i]\n",
    "                img_path = pred['image_path']\n",
    "                img = Image.open(img_path)\n",
    "                \n",
    "                plt.subplot(sample_high + sample_low, 2, (sample_high + i)*2 + 1)\n",
    "                plt.imshow(img)\n",
    "                plt.title(f\"Low Confidence Sample {i+1}\")\n",
    "                plt.axis('off')\n",
    "                \n",
    "                plt.subplot(sample_high + sample_low, 2, (sample_high + i)*2 + 2)\n",
    "                plt.text(0.5, 0.5,\n",
    "                       f\"Predicted: {pred['predicted_class']}\\nConfidence: {pred['confidence']:.2%}\",\n",
    "                       ha='center', va='center', fontsize=12)\n",
    "                plt.axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save the visualization\n",
    "            conf_samples_file = os.path.join(save_dir, 'confidence_samples.png')\n",
    "            plt.savefig(conf_samples_file, dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing batch results: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff69934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 5: Handwritten Text Recognition ---\n",
    "\"\"\"\n",
    "## Handwritten Text Recognition\n",
    "\n",
    "Recognize characters in handwritten text images.\n",
    "This section includes functions for character segmentation and recognition.\n",
    "\"\"\"\n",
    "\n",
    "def recognize_handwritten_text(model, class_names, image_path, save_dir=\"inference_results/text\"):\n",
    "    \"\"\"\n",
    "    Recognize characters in a handwritten text image.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        class_names: List of class names\n",
    "        image_path: Path to the handwritten text image\n",
    "        save_dir: Directory to save the results\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (detected_text, character_info, visualization_images)\n",
    "    \"\"\"\n",
    "    print(f\"Recognizing handwritten text in image: {image_path}\")\n",
    "    \n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"ERROR: Image file '{image_path}' not found\")\n",
    "        return None, None, None\n",
    "    \n",
    "    try:\n",
    "        # Extract and classify characters using the utility function\n",
    "        detected_text, character_info, visualization_images = extract_characters_from_image(\n",
    "            image_path=image_path,\n",
    "            model=model,\n",
    "            class_names=class_names,\n",
    "            device=device,\n",
    "            spacing=24,\n",
    "            min_area=50,\n",
    "            normalization_type='imagenet',\n",
    "            visualize=True,\n",
    "            output_dir=os.path.join(save_dir, os.path.basename(image_path).split('.')[0])\n",
    "        )\n",
    "        \n",
    "        # Create a complete visualization\n",
    "        if visualization_images:\n",
    "            # Create a grid of images\n",
    "            fig = create_visualization_grid(\n",
    "                visualization_images,\n",
    "                grid_cols=2,\n",
    "                figsize=(15, 5 * ((len(visualization_images) + 1) // 2)),\n",
    "                save_path=os.path.join(save_dir, f\"recognition_{os.path.basename(image_path)}\")\n",
    "            )\n",
    "            \n",
    "            plt.show()\n",
    "        \n",
    "        print(f\"Recognized text: {detected_text}\")\n",
    "        \n",
    "        return detected_text, character_info, visualization_images\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error recognizing handwritten text: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None, None\n",
    "\n",
    "def recognize_multiple_text_images(model, class_names, image_folder, save_dir=\"inference_results/text\"):\n",
    "    \"\"\"\n",
    "    Recognize characters in multiple handwritten text images.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        class_names: List of class names\n",
    "        image_folder: Path to the folder containing text images\n",
    "        save_dir: Directory to save the results\n",
    "        \n",
    "    Returns:\n",
    "        dict: Recognition results for all images\n",
    "    \"\"\"\n",
    "    print(f\"Recognizing handwritten text in images from: {image_folder}\")\n",
    "    \n",
    "    if not os.path.exists(image_folder):\n",
    "        print(f\"ERROR: Image folder '{image_folder}' not found\")\n",
    "        return None\n",
    "    \n",
    "    # Find all image files\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff', '.gif']\n",
    "    image_paths = []\n",
    "    \n",
    "    for ext in image_extensions:\n",
    "        image_paths.extend(glob(os.path.join(image_folder, f\"*{ext}\")))\n",
    "        image_paths.extend(glob(os.path.join(image_folder, f\"*{ext.upper()}\")))\n",
    "    \n",
    "    if not image_paths:\n",
    "        print(f\"ERROR: No image files found in '{image_folder}'\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Found {len(image_paths)} images for text recognition\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for img_path in image_paths:\n",
    "        print(f\"Processing: {os.path.basename(img_path)}\")\n",
    "        \n",
    "        detected_text, character_info, _ = recognize_handwritten_text(\n",
    "            model=model,\n",
    "            class_names=class_names,\n",
    "            image_path=img_path,\n",
    "            save_dir=save_dir\n",
    "        )\n",
    "        \n",
    "        if detected_text is not None:\n",
    "            results[img_path] = {\n",
    "                'text': detected_text,\n",
    "                'characters': len(character_info),\n",
    "                'character_info': character_info\n",
    "            }\n",
    "    \n",
    "    # Save results to JSON\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    results_file = os.path.join(save_dir, 'text_recognition_results.json')\n",
    "    \n",
    "    with open(results_file, 'w') as f:\n",
    "        # Convert character_info to serializable format\n",
    "        serializable_results = {}\n",
    "        for path, info in results.items():\n",
    "            char_info = []\n",
    "            for char_data in info['character_info']:\n",
    "                char_info.append({\n",
    "                    'character': char_data['character'],\n",
    "                    'confidence': char_data['confidence'],\n",
    "                    'bbox': list(char_data['bbox']),\n",
    "                    'index': char_data['index']\n",
    "                })\n",
    "            \n",
    "            serializable_results[path] = {\n",
    "                'text': info['text'],\n",
    "                'characters': info['characters'],\n",
    "                'character_info': char_info\n",
    "            }\n",
    "        \n",
    "        json.dump(serializable_results, f, indent=2)\n",
    "    \n",
    "    print(f\"Text recognition results saved to {results_file}\")\n",
    "    \n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f590e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 6: Model Analysis and Benchmarking ---\n",
    "\"\"\"\n",
    "## Model Analysis and Benchmarking\n",
    "\n",
    "Analyze model performance and benchmark inference speed.\n",
    "This section includes functions for visualizing model confidence and measuring inference time.\n",
    "\"\"\"\n",
    "\n",
    "def visualize_model_confidence(model, class_names, image_path, save_dir=\"inference_results/single\"):\n",
    "    \"\"\"\n",
    "    Visualize model confidence across all classes for a single image.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        class_names: List of class names\n",
    "        image_path: Path to the input image\n",
    "        save_dir: Directory to save the results\n",
    "        \n",
    "    Returns:\n",
    "        dict: Confidence scores for all classes\n",
    "    \"\"\"\n",
    "    print(f\"Visualizing model confidence for image: {image_path}\")\n",
    "    \n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"ERROR: Image file '{image_path}' not found\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Load and preprocess the image\n",
    "        img_tensor = prepare_single_image(image_path, normalization_type='imagenet', device=device)\n",
    "        \n",
    "        # Get top-k predictions\n",
    "        model.eval()\n",
    "        top_predictions = get_top_k_predictions(\n",
    "            model=model,\n",
    "            image_tensor=img_tensor,\n",
    "            class_names=class_names,\n",
    "            k=len(class_names),  # Get all classes\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        # Sort predictions by confidence\n",
    "        sorted_predictions = sorted(top_predictions, key=lambda x: x['confidence'], reverse=True)\n",
    "        \n",
    "        # Display the image\n",
    "        img = Image.open(image_path)\n",
    "        \n",
    "        plt.figure(figsize=(15, 8))\n",
    "        \n",
    "        # Original image\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(\"Input Image\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Confidence distribution\n",
    "        plt.subplot(1, 2, 2)\n",
    "        \n",
    "        # Get top 10 and bottom 5 predictions for clarity\n",
    "        top_10 = sorted_predictions[:10]\n",
    "        bottom_5 = sorted_predictions[-5:]\n",
    "        \n",
    "        # Create a combined list\n",
    "        display_preds = top_10 + bottom_5\n",
    "        \n",
    "        # Remove duplicates if any\n",
    "        display_preds = [dict(t) for t in {tuple(d.items()) for d in display_preds}]\n",
    "        \n",
    "        # Sort again\n",
    "        display_preds = sorted(display_preds, key=lambda x: x['confidence'], reverse=True)\n",
    "        \n",
    "        # Extract classes and confidences\n",
    "        classes = [pred['class'] for pred in display_preds]\n",
    "        confidences = [pred['confidence'] for pred in display_preds]\n",
    "        \n",
    "        # Create a colormap (green for high confidence, red for low)\n",
    "        colors = ['green' if i < 3 else 'skyblue' if i < 10 else 'red' for i in range(len(display_preds))]\n",
    "        \n",
    "        plt.barh(range(len(classes)), confidences, color=colors)\n",
    "        plt.yticks(range(len(classes)), classes)\n",
    "        plt.xlim(0, 1)\n",
    "        plt.xlabel(\"Confidence\")\n",
    "        plt.title(\"Model Confidence Distribution\")\n",
    "        plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # Add values on the bars\n",
    "        for i, v in enumerate(confidences):\n",
    "            plt.text(v + 0.01, i, f\"{v:.2%}\", va='center')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the visualization\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        basename = os.path.basename(image_path)\n",
    "        save_path = os.path.join(save_dir, f\"confidence_{basename}\")\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        print(f\"Confidence visualization saved to {save_path}\")\n",
    "        plt.show()\n",
    "        \n",
    "        # Return all confidence scores\n",
    "        confidence_scores = {pred['class']: pred['confidence'] for pred in sorted_predictions}\n",
    "        return confidence_scores\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error visualizing model confidence: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "def benchmark_model_performance(model, image_path, class_names, device=device, \n",
    "                              num_iterations=100, save_dir=\"inference_results\"):\n",
    "    \"\"\"\n",
    "    Benchmark model inference speed.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        image_path: Path to a sample image for benchmarking\n",
    "        class_names: List of class names\n",
    "        device: Device to run the benchmark on\n",
    "        num_iterations: Number of inference iterations\n",
    "        save_dir: Directory to save the results\n",
    "        \n",
    "    Returns:\n",
    "        dict: Benchmark results\n",
    "    \"\"\"\n",
    "    print(f\"Benchmarking model performance on device: {device}\")\n",
    "    \n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"ERROR: Sample image '{image_path}' not found\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Run the benchmark using the utility function\n",
    "        benchmark_results = benchmark_inference_speed(\n",
    "            model=model,\n",
    "            sample_image_path=image_path,\n",
    "            class_names=class_names,\n",
    "            device=device,\n",
    "            num_iterations=num_iterations,\n",
    "            warmup_iterations=10\n",
    "        )\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"Benchmark results:\")\n",
    "        print(f\"  Total time: {benchmark_results['total_time']:.4f} seconds\")\n",
    "        print(f\"  Average time per inference: {benchmark_results['avg_time_per_inference']*1000:.2f} ms\")\n",
    "        print(f\"  Frames per second (FPS): {benchmark_results['fps']:.2f}\")\n",
    "        \n",
    "        # Create visualization\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        plt.bar(['Time per inference (ms)', 'FPS'], \n",
    "              [benchmark_results['avg_time_per_inference']*1000, benchmark_results['fps']],\n",
    "              color=['skyblue', 'green'])\n",
    "        \n",
    "        plt.ylabel(\"Value\")\n",
    "        plt.title(f\"Model Performance on {device} ({num_iterations} iterations)\")\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # Add values on the bars\n",
    "        plt.text(0, benchmark_results['avg_time_per_inference']*1000 + 1, \n",
    "               f\"{benchmark_results['avg_time_per_inference']*1000:.2f} ms\",\n",
    "               ha='center', va='bottom')\n",
    "        \n",
    "        plt.text(1, benchmark_results['fps'] + 1, \n",
    "               f\"{benchmark_results['fps']:.2f} FPS\",\n",
    "               ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the visualization\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        save_path = os.path.join(save_dir, f\"benchmark_{device}.png\")\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        print(f\"Benchmark visualization saved to {save_path}\")\n",
    "        plt.show()\n",
    "        \n",
    "        return benchmark_results\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error benchmarking model: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "def compare_models_performance(models_configs, image_path, save_dir=\"inference_results\"):\n",
    "    \"\"\"\n",
    "    Compare the performance of multiple models.\n",
    "    \n",
    "    Args:\n",
    "        models_configs: List of model configurations\n",
    "            [{'name': 'model_name', 'model': model_instance, 'class_names': class_names}, ...]\n",
    "        image_path: Path to a sample image for benchmarking\n",
    "        save_dir: Directory to save the results\n",
    "        \n",
    "    Returns:\n",
    "        dict: Comparison results\n",
    "    \"\"\"\n",
    "    print(f\"Comparing performance of {len(models_configs)} models\")\n",
    "    \n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"ERROR: Sample image '{image_path}' not found\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        comparison_results = {}\n",
    "        \n",
    "        for config in models_configs:\n",
    "            model_name = config['name']\n",
    "            model = config['model']\n",
    "            class_names = config['class_names']\n",
    "            \n",
    "            print(f\"\\nBenchmarking model: {model_name}\")\n",
    "            \n",
    "            # Run the benchmark\n",
    "            results = benchmark_inference_speed(\n",
    "                model=model,\n",
    "                sample_image_path=image_path,\n",
    "                class_names=class_names,\n",
    "                device=device,\n",
    "                num_iterations=50,\n",
    "                warmup_iterations=5\n",
    "            )\n",
    "            \n",
    "            comparison_results[model_name] = results\n",
    "            \n",
    "            print(f\"  Average time per inference: {results['avg_time_per_inference']*1000:.2f} ms\")\n",
    "            print(f\"  Frames per second (FPS): {results['fps']:.2f}\")\n",
    "        \n",
    "        # Create visualization\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Prepare data for plotting\n",
    "        model_names = list(comparison_results.keys())\n",
    "        avg_times = [results['avg_time_per_inference']*1000 for results in comparison_results.values()]\n",
    "        fps_values = [results['fps'] for results in comparison_results.values()]\n",
    "        \n",
    "        # Create a subplot for average inference time\n",
    "        plt.subplot(1, 2, 1)\n",
    "        bars = plt.bar(model_names, avg_times, color='skyblue')\n",
    "        plt.ylabel(\"Time (ms)\")\n",
    "        plt.title(\"Average Inference Time\")\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # Add values on the bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                   f\"{height:.2f} ms\", ha='center', va='bottom')\n",
    "        \n",
    "        # Create a subplot for FPS\n",
    "        plt.subplot(1, 2, 2)\n",
    "        bars = plt.bar(model_names, fps_values, color='green')\n",
    "        plt.ylabel(\"FPS\")\n",
    "        plt.title(\"Frames Per Second\")\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # Add values on the bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                   f\"{height:.2f}\", ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the visualization\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        save_path = os.path.join(save_dir, \"model_comparison.png\")\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        print(f\"Model comparison saved to {save_path}\")\n",
    "        plt.show()\n",
    "        \n",
    "        return comparison_results\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error comparing models: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc1029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 7: Complete Inference Pipeline ---\n",
    "\"\"\"\n",
    "## Complete Inference Pipeline\n",
    "\n",
    "This section demonstrates a complete inference pipeline from model loading to prediction.\n",
    "Follow this example to perform inference on your own images.\n",
    "\"\"\"\n",
    "\n",
    "def run_complete_inference_pipeline(model_name, checkpoint_type=\"best\", \n",
    "                                  image_path=None, image_folder=None, \n",
    "                                  model_checkpoints_dir=\"model_checkpoints\",\n",
    "                                  save_dir=\"inference_results\"):\n",
    "    \"\"\"\n",
    "    Run a complete inference pipeline from model loading to prediction.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name of the model to use\n",
    "        checkpoint_type: Type of checkpoint to use ('best', 'final', or specific path)\n",
    "        image_path: Path to a single image for inference (optional)\n",
    "        image_folder: Path to a folder of images for batch inference (optional)\n",
    "        model_checkpoints_dir: Directory containing model checkpoints\n",
    "        save_dir: Directory to save the results\n",
    "        \n",
    "    Returns:\n",
    "        dict: Inference results\n",
    "    \"\"\"\n",
    "    print(f\"Running complete inference pipeline with model: {model_name}\")\n",
    "    \n",
    "    # Step 1: Load the model and class names\n",
    "    print(\"\\nStep 1: Loading model and class names...\")\n",
    "    model, class_names = load_inference_model(model_name, checkpoint_type, model_checkpoints_dir)\n",
    "    \n",
    "    if model is None or class_names is None:\n",
    "        print(\"Failed to load model or class names. Aborting inference.\")\n",
    "        return None\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Step 2: Single image inference (if provided)\n",
    "    if image_path is not None:\n",
    "        print(f\"\\nStep 2: Running inference on single image: {image_path}\")\n",
    "        \n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"ERROR: Image file '{image_path}' not found\")\n",
    "        else:\n",
    "            # Perform inference\n",
    "            single_result = infer_single_image(\n",
    "                model=model,\n",
    "                class_names=class_names,\n",
    "                image_path=image_path,\n",
    "                save_dir=os.path.join(save_dir, \"single\")\n",
    "            )\n",
    "            \n",
    "            if single_result is not None:\n",
    "                results['single_image'] = single_result\n",
    "                \n",
    "                # Visualize model confidence\n",
    "                confidence_scores = visualize_model_confidence(\n",
    "                    model=model,\n",
    "                    class_names=class_names,\n",
    "                    image_path=image_path,\n",
    "                    save_dir=os.path.join(save_dir, \"single\")\n",
    "                )\n",
    "                \n",
    "                if confidence_scores is not None:\n",
    "                    results['confidence_scores'] = confidence_scores\n",
    "    \n",
    "    # Step 3: Batch inference (if folder provided)\n",
    "    if image_folder is not None:\n",
    "        print(f\"\\nStep 3: Running batch inference on images in: {image_folder}\")\n",
    "        \n",
    "        if not os.path.exists(image_folder):\n",
    "            print(f\"ERROR: Image folder '{image_folder}' not found\")\n",
    "        else:\n",
    "            # Perform batch inference\n",
    "            batch_results = infer_batch_images(\n",
    "                model=model,\n",
    "                class_names=class_names,\n",
    "                image_folder=image_folder,\n",
    "                save_dir=os.path.join(save_dir, \"batch\"),\n",
    "                batch_size=16,\n",
    "                visualize=True\n",
    "            )\n",
    "            \n",
    "            if batch_results is not None:\n",
    "                results['batch_results'] = {\n",
    "                    'count': len(batch_results),\n",
    "                    'file': os.path.join(save_dir, \"batch\", \"batch_results.json\")\n",
    "                }\n",
    "    \n",
    "    # Step 4: Benchmark model performance\n",
    "    print(\"\\nStep 4: Benchmarking model performance...\")\n",
    "    \n",
    "    if image_path is not None:\n",
    "        benchmark_results = benchmark_model_performance(\n",
    "            model=model,\n",
    "            image_path=image_path,\n",
    "            class_names=class_names,\n",
    "            device=device,\n",
    "            num_iterations=100,\n",
    "            save_dir=save_dir\n",
    "        )\n",
    "        \n",
    "        if benchmark_results is not None:\n",
    "            results['benchmark'] = benchmark_results\n",
    "    \n",
    "    print(\"\\nInference pipeline completed successfully.\")\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a379bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 8: Run Inference (User Code) ---\n",
    "\"\"\"\n",
    "## Run Inference\n",
    "\n",
    "This is where you run the actual inference pipeline with your trained models and images.\n",
    "Uncomment and modify the code below to perform inference on your own images.\n",
    "\"\"\"\n",
    "\n",
    "# Option 1: Run complete inference pipeline\n",
    "\"\"\"\n",
    "results = run_complete_inference_pipeline(\n",
    "    model_name='improved_cnn',  # Replace with your model name\n",
    "    checkpoint_type='best',\n",
    "    image_path='path/to/your/image.jpg',  # Replace with your image path\n",
    "    image_folder=None,  # Optionally specify a folder for batch inference\n",
    "    model_checkpoints_dir='model_checkpoints',\n",
    "    save_dir='inference_results'\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Option 2: Load model and perform specific inference tasks\n",
    "\"\"\"\n",
    "# Load model\n",
    "model_name = 'improved_cnn'  # Replace with your model name\n",
    "checkpoint_path = 'model_checkpoints/improved_cnn/best_model.pth'  # Replace with your checkpoint path\n",
    "class_names_path = 'model_checkpoints/improved_cnn/class_names.txt'  # Replace with your class names path\n",
    "\n",
    "# Load class names\n",
    "class_names = load_class_names(class_names_path)\n",
    "\n",
    "# Determine number of classes\n",
    "num_classes = len(class_names) if class_names else 62  # Default to 62 classes (10 digits + 26*2 letters)\n",
    "\n",
    "# Load model\n",
    "model = load_model_checkpoint(checkpoint_path, model_name, num_classes, device)\n",
    "\n",
    "# Single image inference\n",
    "image_path = 'path/to/your/image.jpg'  # Replace with your image path\n",
    "prediction = infer_single_image(model, class_names, image_path)\n",
    "\n",
    "# Batch inference\n",
    "image_folder = 'path/to/your/images'  # Replace with your image folder\n",
    "batch_results = infer_batch_images(model, class_names, image_folder)\n",
    "\n",
    "# Handwritten text recognition\n",
    "text_image_path = 'path/to/your/text_image.jpg'  # Replace with your text image path\n",
    "recognized_text, character_info, visualization_images = recognize_handwritten_text(\n",
    "    model, class_names, text_image_path\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Option 3: Compare multiple models\n",
    "\"\"\"\n",
    "# Load models\n",
    "models_configs = []\n",
    "\n",
    "# Model 1: Basic CNN\n",
    "model1_name = 'basic_cnn'\n",
    "model1_path = 'model_checkpoints/basic_cnn/best_model.pth'\n",
    "class_names1_path = 'model_checkpoints/basic_cnn/class_names.txt'\n",
    "class_names1 = load_class_names(class_names1_path)\n",
    "num_classes1 = len(class_names1)\n",
    "model1 = load_model_checkpoint(model1_path, model1_name, num_classes1, device)\n",
    "if model1 is not None:\n",
    "    models_configs.append({\n",
    "        'name': model1_name,\n",
    "        'model': model1,\n",
    "        'class_names': class_names1\n",
    "    })\n",
    "\n",
    "# Model 2: Improved CNN\n",
    "model2_name = 'improved_cnn'\n",
    "model2_path = 'model_checkpoints/improved_cnn/best_model.pth'\n",
    "class_names2_path = 'model_checkpoints/improved_cnn/class_names.txt'\n",
    "class_names2 = load_class_names(class_names2_path)\n",
    "num_classes2 = len(class_names2)\n",
    "model2 = load_model_checkpoint(model2_path, model2_name, num_classes2, device)\n",
    "if model2 is not None:\n",
    "    models_configs.append({\n",
    "        'name': model2_name,\n",
    "        'model': model2,\n",
    "        'class_names': class_names2\n",
    "    })\n",
    "\n",
    "# Model 3: VGG19\n",
    "model3_name = 'vgg19'\n",
    "model3_path = 'model_checkpoints/vgg19/best_model.pth'\n",
    "class_names3_path = 'model_checkpoints/vgg19/class_names.txt'\n",
    "class_names3 = load_class_names(class_names3_path)\n",
    "num_classes3 = len(class_names3)\n",
    "model3 = load_model_checkpoint(model3_path, model3_name, num_classes3, device)\n",
    "if model3 is not None:\n",
    "    models_configs.append({\n",
    "        'name': model3_name,\n",
    "        'model': model3,\n",
    "        'class_names': class_names3\n",
    "    })\n",
    "\n",
    "# Compare models\n",
    "sample_image_path = 'path/to/your/sample_image.jpg'  # Replace with your sample image path\n",
    "comparison_results = compare_models_performance(models_configs, sample_image_path)\n",
    "\"\"\"\n",
    "\n",
    "print(\"This notebook is ready for inference with handwritten character recognition models.\")\n",
    "print(\"Uncomment one of the inference options above and run this cell to start inference.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
