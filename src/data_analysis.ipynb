{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bedbc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 1: Import Libraries and Set Up Environment ---\n",
    "\"\"\"\n",
    "# Handwritten Character Recognition: Data Analysis Notebook\n",
    "\n",
    "This notebook focuses on data analysis, preprocessing, and visualization for handwritten character recognition.\n",
    "It explores dataset characteristics, demonstrates transformations, and showcases data augmentation techniques.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import cv2\n",
    "from PIL import Image, ImageOps, ImageEnhance, ImageFilter\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "# Import utility modules\n",
    "from data_utils_file import HandwritingDataPipeline, get_class_labels_from_directory\n",
    "from data_utils_file import RandomChoice, ThicknessTransform, create_custom_transforms\n",
    "\n",
    "# For reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Create directories for saving visualizations\n",
    "os.makedirs(\"data_analysis\", exist_ok=True)\n",
    "os.makedirs(\"data_analysis/transformations\", exist_ok=True)\n",
    "os.makedirs(\"data_analysis/augmentations\", exist_ok=True)\n",
    "os.makedirs(\"data_analysis/statistics\", exist_ok=True)\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.set_palette(\"muted\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5624d853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 2: Data Loading and Exploration ---\n",
    "\"\"\"\n",
    "## Data Loading and Exploration\n",
    "\n",
    "In this section, we'll load the handwritten character dataset and explore its basic properties:\n",
    "- Dataset structure and size\n",
    "- Class distribution\n",
    "- Sample images from each class\n",
    "\"\"\"\n",
    "\n",
    "def load_and_explore_dataset(data_root):\n",
    "    \"\"\"\n",
    "    Load and explore the handwritten character dataset.\n",
    "    \n",
    "    Args:\n",
    "        data_root: Path to the dataset root directory\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (dataset, class_names, stats)\n",
    "    \"\"\"\n",
    "    print(f\"Loading dataset from: {data_root}\")\n",
    "    \n",
    "    if not os.path.exists(data_root):\n",
    "        print(f\"ERROR: Data root directory '{data_root}' not found\")\n",
    "        return None, None, None\n",
    "    \n",
    "    try:\n",
    "        # Get class names from directory structure\n",
    "        class_names = get_class_labels_from_directory(data_root)\n",
    "        print(f\"Found {len(class_names)} classes: {', '.join(class_names[:10])}...\")\n",
    "        \n",
    "        # Load dataset using ImageFolder\n",
    "        dataset = datasets.ImageFolder(root=data_root)\n",
    "        print(f\"Dataset loaded with {len(dataset)} samples\")\n",
    "        \n",
    "        # Calculate class distribution\n",
    "        class_counts = Counter()\n",
    "        for _, label in dataset.samples:\n",
    "            class_counts[dataset.classes[label]] += 1\n",
    "        \n",
    "        # Get basic dataset statistics\n",
    "        stats = {\n",
    "            'total_samples': len(dataset),\n",
    "            'num_classes': len(class_names),\n",
    "            'class_counts': dict(class_counts),\n",
    "            'min_samples_per_class': min(class_counts.values()),\n",
    "            'max_samples_per_class': max(class_counts.values()),\n",
    "            'avg_samples_per_class': sum(class_counts.values()) / len(class_counts)\n",
    "        }\n",
    "        \n",
    "        print(f\"Dataset statistics:\")\n",
    "        print(f\"  Total samples: {stats['total_samples']}\")\n",
    "        print(f\"  Number of classes: {stats['num_classes']}\")\n",
    "        print(f\"  Min samples per class: {stats['min_samples_per_class']}\")\n",
    "        print(f\"  Max samples per class: {stats['max_samples_per_class']}\")\n",
    "        print(f\"  Avg samples per class: {stats['avg_samples_per_class']:.2f}\")\n",
    "        \n",
    "        return dataset, class_names, stats\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error exploring dataset: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None, None\n",
    "\n",
    "def visualize_class_distribution(stats, save_path=None):\n",
    "    \"\"\"Visualize the class distribution as a histogram.\"\"\"\n",
    "    if not stats or 'class_counts' not in stats:\n",
    "        print(\"No statistics available for visualization\")\n",
    "        return\n",
    "    \n",
    "    class_counts = stats['class_counts']\n",
    "    \n",
    "    # Sort by count for better visualization\n",
    "    sorted_counts = dict(sorted(class_counts.items(), key=lambda x: x[1], reverse=True))\n",
    "    \n",
    "    # Plot histogram of class distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # If we have too many classes, limit the display\n",
    "    if len(sorted_counts) > 30:\n",
    "        # Show top 15 and bottom 15 classes\n",
    "        top_classes = list(sorted_counts.keys())[:15]\n",
    "        bottom_classes = list(sorted_counts.keys())[-15:]\n",
    "        selected_classes = top_classes + bottom_classes\n",
    "        selected_counts = {cls: sorted_counts[cls] for cls in selected_classes}\n",
    "        \n",
    "        bars = plt.bar(range(len(selected_counts)), selected_counts.values())\n",
    "        plt.xticks(range(len(selected_counts)), selected_counts.keys(), rotation=90)\n",
    "        \n",
    "        # Add a text annotation indicating that middle classes are omitted\n",
    "        mid_point = len(top_classes) - 0.5\n",
    "        plt.axvline(x=mid_point, color='red', linestyle='--')\n",
    "        plt.text(mid_point, max(selected_counts.values())/2, 'Middle classes omitted', \n",
    "                rotation=90, verticalalignment='center', horizontalalignment='center')\n",
    "    else:\n",
    "        bars = plt.bar(range(len(sorted_counts)), sorted_counts.values())\n",
    "        plt.xticks(range(len(sorted_counts)), sorted_counts.keys(), rotation=90)\n",
    "    \n",
    "    # Add count labels on top of bars\n",
    "    for i, bar in enumerate(bars):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 5,\n",
    "                f'{height}', ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Number of Samples')\n",
    "    plt.title('Class Distribution in Dataset')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Class distribution saved to {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def visualize_sample_images(dataset, num_classes=10, samples_per_class=5, figsize=(15, 10), save_path=None):\n",
    "    \"\"\"Visualize sample images from each class.\"\"\"\n",
    "    if dataset is None:\n",
    "        print(\"No dataset available for visualization\")\n",
    "        return\n",
    "    \n",
    "    # Organize samples by class\n",
    "    samples_by_class = {}\n",
    "    for idx, (_, label) in enumerate(dataset.samples):\n",
    "        class_name = dataset.classes[label]\n",
    "        if class_name not in samples_by_class:\n",
    "            samples_by_class[class_name] = []\n",
    "        samples_by_class[class_name].append(idx)\n",
    "    \n",
    "    # Limit number of classes to display\n",
    "    selected_classes = list(samples_by_class.keys())[:num_classes]\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(len(selected_classes), samples_per_class, figsize=figsize)\n",
    "    \n",
    "    for i, class_name in enumerate(selected_classes):\n",
    "        # Get random samples for this class\n",
    "        class_indices = random.sample(samples_by_class[class_name], \n",
    "                                     min(samples_per_class, len(samples_by_class[class_name])))\n",
    "        \n",
    "        for j, idx in enumerate(class_indices):\n",
    "            img, _ = dataset[idx]\n",
    "            axes[i, j].imshow(img)\n",
    "            axes[i, j].axis('off')\n",
    "            \n",
    "            # Add class label to the first image in each row\n",
    "            if j == 0:\n",
    "                axes[i, j].set_title(f\"Class: {class_name}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Sample images saved to {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Example usage (commented out)\n",
    "\"\"\"\n",
    "# Specify your dataset path\n",
    "DATA_ROOT = \"./datasets/handwritten-english/augmented_images1\"\n",
    "\n",
    "# Load and explore the dataset\n",
    "dataset, class_names, stats = load_and_explore_dataset(DATA_ROOT)\n",
    "\n",
    "# Visualize class distribution\n",
    "visualize_class_distribution(stats, save_path=\"data_analysis/statistics/class_distribution.png\")\n",
    "\n",
    "# Visualize sample images\n",
    "visualize_sample_images(dataset, num_classes=10, samples_per_class=5, \n",
    "                     save_path=\"data_analysis/statistics/sample_images.png\")\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ac4749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 3: Image Property Analysis ---\n",
    "\"\"\"\n",
    "## Image Property Analysis\n",
    "\n",
    "Analyze the properties of the images in the dataset:\n",
    "- Image sizes and aspect ratios\n",
    "- Pixel intensity distributions\n",
    "- Stroke characteristics\n",
    "\"\"\"\n",
    "\n",
    "def analyze_image_properties(dataset, sample_size=100, save_dir=\"data_analysis/statistics\"):\n",
    "    \"\"\"Analyze various properties of images in the dataset.\"\"\"\n",
    "    if dataset is None or len(dataset) == 0:\n",
    "        print(\"No dataset available for analysis\")\n",
    "        return None\n",
    "    \n",
    "    # Randomly sample images for analysis\n",
    "    sample_indices = random.sample(range(len(dataset)), min(sample_size, len(dataset)))\n",
    "    \n",
    "    # Image properties to collect\n",
    "    widths = []\n",
    "    heights = []\n",
    "    aspect_ratios = []\n",
    "    mean_intensities = []\n",
    "    std_intensities = []\n",
    "    histograms = []\n",
    "    \n",
    "    for idx in sample_indices:\n",
    "        img, _ = dataset[idx]\n",
    "        \n",
    "        # Convert PIL image to numpy array if needed\n",
    "        if isinstance(img, Image.Image):\n",
    "            img_np = np.array(img.convert('L'))\n",
    "        else:\n",
    "            img_np = img\n",
    "        \n",
    "        # Image dimensions\n",
    "        h, w = img_np.shape[:2]\n",
    "        widths.append(w)\n",
    "        heights.append(h)\n",
    "        aspect_ratios.append(w/h)\n",
    "        \n",
    "        # Pixel intensity statistics\n",
    "        mean_intensities.append(np.mean(img_np))\n",
    "        std_intensities.append(np.std(img_np))\n",
    "        \n",
    "        # Calculate histogram\n",
    "        hist, _ = np.histogram(img_np.flatten(), bins=256, range=[0, 256])\n",
    "        histograms.append(hist)\n",
    "    \n",
    "    # Combine histograms\n",
    "    avg_histogram = np.mean(histograms, axis=0)\n",
    "    \n",
    "    # Create results dictionary\n",
    "    results = {\n",
    "        'width': {\n",
    "            'mean': np.mean(widths),\n",
    "            'std': np.std(widths),\n",
    "            'min': np.min(widths),\n",
    "            'max': np.max(widths),\n",
    "            'values': widths\n",
    "        },\n",
    "        'height': {\n",
    "            'mean': np.mean(heights),\n",
    "            'std': np.std(heights),\n",
    "            'min': np.min(heights),\n",
    "            'max': np.max(heights),\n",
    "            'values': heights\n",
    "        },\n",
    "        'aspect_ratio': {\n",
    "            'mean': np.mean(aspect_ratios),\n",
    "            'std': np.std(aspect_ratios),\n",
    "            'min': np.min(aspect_ratios),\n",
    "            'max': np.max(aspect_ratios),\n",
    "            'values': aspect_ratios\n",
    "        },\n",
    "        'mean_intensity': {\n",
    "            'mean': np.mean(mean_intensities),\n",
    "            'std': np.std(mean_intensities),\n",
    "            'min': np.min(mean_intensities),\n",
    "            'max': np.max(mean_intensities),\n",
    "            'values': mean_intensities\n",
    "        },\n",
    "        'std_intensity': {\n",
    "            'mean': np.mean(std_intensities),\n",
    "            'std': np.std(std_intensities),\n",
    "            'min': np.min(std_intensities),\n",
    "            'max': np.max(std_intensities),\n",
    "            'values': std_intensities\n",
    "        },\n",
    "        'avg_histogram': avg_histogram\n",
    "    }\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"Image Property Analysis:\")\n",
    "    print(f\"  Width (pixels): mean={results['width']['mean']:.2f}, std={results['width']['std']:.2f}, \"\n",
    "          f\"min={results['width']['min']}, max={results['width']['max']}\")\n",
    "    print(f\"  Height (pixels): mean={results['height']['mean']:.2f}, std={results['height']['std']:.2f}, \"\n",
    "          f\"min={results['height']['min']}, max={results['height']['max']}\")\n",
    "    print(f\"  Aspect Ratio (w/h): mean={results['aspect_ratio']['mean']:.2f}, std={results['aspect_ratio']['std']:.2f}, \"\n",
    "          f\"min={results['aspect_ratio']['min']:.2f}, max={results['aspect_ratio']['max']:.2f}\")\n",
    "    print(f\"  Mean Intensity: mean={results['mean_intensity']['mean']:.2f}, std={results['mean_intensity']['std']:.2f}\")\n",
    "    print(f\"  Std Intensity: mean={results['std_intensity']['mean']:.2f}, std={results['std_intensity']['std']:.2f}\")\n",
    "    \n",
    "    # Create visualizations\n",
    "    # 1. Size distribution\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.hist(widths, bins=20, alpha=0.7, color='blue')\n",
    "    plt.axvline(x=np.mean(widths), color='red', linestyle='--')\n",
    "    plt.xlabel('Width (pixels)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Width Distribution (mean={np.mean(widths):.1f})')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.hist(heights, bins=20, alpha=0.7, color='green')\n",
    "    plt.axvline(x=np.mean(heights), color='red', linestyle='--')\n",
    "    plt.xlabel('Height (pixels)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Height Distribution (mean={np.mean(heights):.1f})')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.hist(aspect_ratios, bins=20, alpha=0.7, color='purple')\n",
    "    plt.axvline(x=np.mean(aspect_ratios), color='red', linestyle='--')\n",
    "    plt.xlabel('Aspect Ratio (width/height)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Aspect Ratio Distribution (mean={np.mean(aspect_ratios):.2f})')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_dir}/size_distributions.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. Intensity distributions\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.hist(mean_intensities, bins=20, alpha=0.7, color='orange')\n",
    "    plt.axvline(x=np.mean(mean_intensities), color='red', linestyle='--')\n",
    "    plt.xlabel('Mean Intensity')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Mean Intensity Distribution (mean={np.mean(mean_intensities):.1f})')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.hist(std_intensities, bins=20, alpha=0.7, color='cyan')\n",
    "    plt.axvline(x=np.mean(std_intensities), color='red', linestyle='--')\n",
    "    plt.xlabel('Std Intensity')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Std Intensity Distribution (mean={np.mean(std_intensities):.1f})')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.bar(range(256), avg_histogram, alpha=0.7, color='teal')\n",
    "    plt.xlabel('Pixel Intensity')\n",
    "    plt.ylabel('Average Frequency')\n",
    "    plt.title('Average Intensity Histogram')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_dir}/intensity_distributions.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "def extract_stroke_features(dataset, sample_size=20, save_dir=\"data_analysis/statistics\"):\n",
    "    \"\"\"Extract and analyze stroke features in handwritten characters.\"\"\"\n",
    "    if dataset is None or len(dataset) == 0:\n",
    "        print(\"No dataset available for analysis\")\n",
    "        return None\n",
    "    \n",
    "    # Randomly sample images for analysis\n",
    "    sample_indices = random.sample(range(len(dataset)), min(sample_size, len(dataset)))\n",
    "    \n",
    "    # Features to extract\n",
    "    stroke_thickness = []\n",
    "    stroke_continuity = []  # Measured by number of contours\n",
    "    character_density = []  # Ratio of foreground to total pixels\n",
    "    \n",
    "    # Visualization samples\n",
    "    vis_samples = []\n",
    "    \n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        img, label = dataset[idx]\n",
    "        class_name = dataset.classes[label]\n",
    "        \n",
    "        # Convert PIL image to numpy array\n",
    "        if isinstance(img, Image.Image):\n",
    "            img_np = np.array(img.convert('L'))\n",
    "        else:\n",
    "            img_np = img\n",
    "        \n",
    "        # Ensure binary image (black text on white background)\n",
    "        _, binary = cv2.threshold(img_np, 128, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # Invert for processing (white text on black background)\n",
    "        binary_inv = cv2.bitwise_not(binary)\n",
    "        \n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(binary_inv, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Measure stroke thickness using distance transform\n",
    "        dist_transform = cv2.distanceTransform(binary_inv, cv2.DIST_L2, 5)\n",
    "        max_thickness = np.max(dist_transform) * 2  # Diameter is twice the radius\n",
    "        \n",
    "        # Calculate character density (ratio of foreground to total pixels)\n",
    "        density = np.sum(binary_inv > 0) / (binary_inv.shape[0] * binary_inv.shape[1])\n",
    "        \n",
    "        # Store features\n",
    "        stroke_thickness.append(max_thickness)\n",
    "        stroke_continuity.append(len(contours))\n",
    "        character_density.append(density)\n",
    "        \n",
    "        # Store visualization samples (first 5)\n",
    "        if i < 5:\n",
    "            # Create visualization of thickness\n",
    "            thickness_vis = cv2.normalize(dist_transform, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "            thickness_vis = cv2.applyColorMap(thickness_vis, cv2.COLORMAP_JET)\n",
    "            \n",
    "            # Original binary image for comparison\n",
    "            binary_rgb = cv2.cvtColor(binary, cv2.COLOR_GRAY2RGB)\n",
    "            \n",
    "            # Draw contours on a copy of the original\n",
    "            contour_img = binary_rgb.copy()\n",
    "            cv2.drawContours(contour_img, contours, -1, (0, 255, 0), 1)\n",
    "            \n",
    "            vis_samples.append({\n",
    "                'class': class_name,\n",
    "                'original': binary_rgb,\n",
    "                'thickness': thickness_vis,\n",
    "                'contours': contour_img,\n",
    "                'features': {\n",
    "                    'max_thickness': max_thickness,\n",
    "                    'num_contours': len(contours),\n",
    "                    'density': density\n",
    "                }\n",
    "            })\n",
    "    \n",
    "    # Compute statistics\n",
    "    results = {\n",
    "        'stroke_thickness': {\n",
    "            'mean': np.mean(stroke_thickness),\n",
    "            'std': np.std(stroke_thickness),\n",
    "            'min': np.min(stroke_thickness),\n",
    "            'max': np.max(stroke_thickness)\n",
    "        },\n",
    "        'stroke_continuity': {\n",
    "            'mean': np.mean(stroke_continuity),\n",
    "            'std': np.std(stroke_continuity),\n",
    "            'min': np.min(stroke_continuity),\n",
    "            'max': np.max(stroke_continuity)\n",
    "        },\n",
    "        'character_density': {\n",
    "            'mean': np.mean(character_density),\n",
    "            'std': np.std(character_density),\n",
    "            'min': np.min(character_density),\n",
    "            'max': np.max(character_density)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"Stroke Feature Analysis:\")\n",
    "    print(f\"  Max Stroke Thickness: mean={results['stroke_thickness']['mean']:.2f} pixels, \"\n",
    "          f\"std={results['stroke_thickness']['std']:.2f}\")\n",
    "    print(f\"  Number of Contours: mean={results['stroke_continuity']['mean']:.2f}, \"\n",
    "          f\"std={results['stroke_continuity']['std']:.2f}\")\n",
    "    print(f\"  Character Density: mean={results['character_density']['mean']:.2f}, \"\n",
    "          f\"std={results['character_density']['std']:.2f}\")\n",
    "    \n",
    "    # Create visualizations\n",
    "    # 1. Feature distributions\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.hist(stroke_thickness, bins=20, alpha=0.7, color='red')\n",
    "    plt.axvline(x=np.mean(stroke_thickness), color='blue', linestyle='--')\n",
    "    plt.xlabel('Max Stroke Thickness (pixels)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Stroke Thickness Distribution')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.hist(stroke_continuity, bins=max(10, max(stroke_continuity)), alpha=0.7, color='green')\n",
    "    plt.axvline(x=np.mean(stroke_continuity), color='blue', linestyle='--')\n",
    "    plt.xlabel('Number of Contours')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Stroke Continuity Distribution')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.hist(character_density, bins=20, alpha=0.7, color='purple')\n",
    "    plt.axvline(x=np.mean(character_density), color='blue', linestyle='--')\n",
    "    plt.xlabel('Character Density')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Character Density Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_dir}/stroke_feature_distributions.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. Visualization samples\n",
    "    if vis_samples:\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        for i, sample in enumerate(vis_samples):\n",
    "            # Original\n",
    "            plt.subplot(5, 3, i*3 + 1)\n",
    "            plt.imshow(sample['original'])\n",
    "            plt.title(f\"Class: {sample['class']}\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # Thickness map\n",
    "            plt.subplot(5, 3, i*3 + 2)\n",
    "            plt.imshow(sample['thickness'])\n",
    "            plt.title(f\"Thickness Map\\nMax: {sample['features']['max_thickness']:.1f}px\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # Contours\n",
    "            plt.subplot(5, 3, i*3 + 3)\n",
    "            plt.imshow(sample['contours'])\n",
    "            plt.title(f\"Contours: {sample['features']['num_contours']}\\nDensity: {sample['features']['density']:.2f}\")\n",
    "            plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{save_dir}/stroke_feature_samples.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage (commented out)\n",
    "\"\"\"\n",
    "# Analyze image properties\n",
    "image_properties = analyze_image_properties(dataset, sample_size=100)\n",
    "\n",
    "# Extract and analyze stroke features\n",
    "stroke_features = extract_stroke_features(dataset, sample_size=20)\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94c35ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 4: Basic Image Transformations ---\n",
    "\"\"\"\n",
    "## Basic Image Transformations\n",
    "\n",
    "Explore the effect of basic image transformations on handwritten characters:\n",
    "- Resizing and scaling\n",
    "- Rotation and affine transformations\n",
    "- Thresholding and binarization\n",
    "- Morphological operations\n",
    "\"\"\"\n",
    "\n",
    "def apply_basic_transformations(img, save_dir=\"data_analysis/transformations\"):\n",
    "    \"\"\"Apply and visualize basic transformations on a single image.\"\"\"\n",
    "    if img is None:\n",
    "        print(\"No image provided for transformations\")\n",
    "        return\n",
    "    \n",
    "    # Convert to PIL image if needed\n",
    "    if not isinstance(img, Image.Image):\n",
    "        img = Image.fromarray(img)\n",
    "    \n",
    "    # Ensure grayscale\n",
    "    img_gray = img.convert('L')\n",
    "    \n",
    "    # Basic transformations\n",
    "    transformations = {\n",
    "        'Original': img_gray,\n",
    "        'Resize (32x32)': img_gray.resize((32, 32), Image.LANCZOS),\n",
    "        'Resize (128x128)': img_gray.resize((128, 128), Image.LANCZOS),\n",
    "        'Rotate (15°)': img_gray.rotate(15, fillcolor=255),\n",
    "        'Rotate (45°)': img_gray.rotate(45, fillcolor=255),\n",
    "        'Invert': ImageOps.invert(img_gray),\n",
    "        'Flip Horizontal': ImageOps.mirror(img_gray),\n",
    "        'Flip Vertical': ImageOps.flip(img_gray),\n",
    "        'Brighten': ImageEnhance.Brightness(img_gray).enhance(1.5),\n",
    "        'Darken': ImageEnhance.Brightness(img_gray).enhance(0.5),\n",
    "        'Contrast+': ImageEnhance.Contrast(img_gray).enhance(2.0),\n",
    "        'Contrast-': ImageEnhance.Contrast(img_gray).enhance(0.5),\n",
    "        'Blur': img_gray.filter(ImageFilter.GaussianBlur(radius=1)),\n",
    "        'Sharpen': img_gray.filter(ImageFilter.SHARPEN),\n",
    "        'Edge Enhance': img_gray.filter(ImageFilter.EDGE_ENHANCE),\n",
    "        'Find Edges': img_gray.filter(ImageFilter.FIND_EDGES),\n",
    "    }\n",
    "    \n",
    "    # Convert to numpy for OpenCV operations\n",
    "    img_np = np.array(img_gray)\n",
    "    \n",
    "    # OpenCV transformations\n",
    "    # Binarization\n",
    "    _, binary_otsu = cv2.threshold(img_np, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    binary_adaptive = cv2.adaptiveThreshold(img_np, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                          cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    # Morphological operations\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    erosion = cv2.erode(img_np, kernel, iterations=1)\n",
    "    dilation = cv2.dilate(img_np, kernel, iterations=1)\n",
    "    opening = cv2.morphologyEx(img_np, cv2.MORPH_OPEN, kernel)\n",
    "    closing = cv2.morphologyEx(img_np, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # Add OpenCV transformations to dictionary\n",
    "    cv2_transforms = {\n",
    "        'Binary (Otsu)': binary_otsu,\n",
    "        'Binary (Adaptive)': binary_adaptive,\n",
    "        'Erosion': erosion,\n",
    "        'Dilation': dilation,\n",
    "        'Opening': opening,\n",
    "        'Closing': closing\n",
    "    }\n",
    "    \n",
    "    # Convert OpenCV results to PIL\n",
    "    for name, img_cv in cv2_transforms.items():\n",
    "        transformations[name] = Image.fromarray(img_cv)\n",
    "    \n",
    "    # Display transformations\n",
    "    n_transforms = len(transformations)\n",
    "    n_cols = 4\n",
    "    n_rows = (n_transforms + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 3 * n_rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, (name, trans_img) in enumerate(transformations.items()):\n",
    "        axes[i].imshow(trans_img, cmap='gray')\n",
    "        axes[i].set_title(name)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(n_transforms, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_dir}/basic_transformations.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return transformations\n",
    "\n",
    "def apply_affine_transformations(img, save_dir=\"data_analysis/transformations\"):\n",
    "    \"\"\"Apply and visualize affine transformations on a single image.\"\"\"\n",
    "    if img is None:\n",
    "        print(\"No image provided for transformations\")\n",
    "        return\n",
    "    \n",
    "    # Convert to PIL image if needed\n",
    "    if not isinstance(img, Image.Image):\n",
    "        img = Image.fromarray(img)\n",
    "    \n",
    "    # Ensure grayscale\n",
    "    img_gray = img.convert('L')\n",
    "    img_np = np.array(img_gray)\n",
    "    \n",
    "    # Get image dimensions\n",
    "    h, w = img_np.shape\n",
    "    \n",
    "    # Affine transformations with OpenCV\n",
    "    transformations = {}\n",
    "    \n",
    "    # Translation\n",
    "    M_right = np.float32([[1, 0, w//4], [0, 1, 0]])\n",
    "    M_down = np.float32([[1, 0, 0], [0, 1, h//4]])\n",
    "    trans_right = cv2.warpAffine(img_np, M_right, (w, h), borderValue=255)\n",
    "    trans_down = cv2.warpAffine(img_np, M_down, (w, h), borderValue=255)\n",
    "    \n",
    "    # Rotation with different centers\n",
    "    center = (w//2, h//2)\n",
    "    M_rot15 = cv2.getRotationMatrix2D(center, 15, 1.0)\n",
    "    M_rot30 = cv2.getRotationMatrix2D(center, 30, 1.0)\n",
    "    M_rot45 = cv2.getRotationMatrix2D(center, 45, 1.0)\n",
    "    rot15 = cv2.warpAffine(img_np, M_rot15, (w, h), borderValue=255)\n",
    "    rot30 = cv2.warpAffine(img_np, M_rot30, (w, h), borderValue=255)\n",
    "    rot45 = cv2.warpAffine(img_np, M_rot45, (w, h), borderValue=255)\n",
    "    \n",
    "    # Scaling\n",
    "    M_scale_up = cv2.getRotationMatrix2D(center, 0, 1.5)\n",
    "    M_scale_down = cv2.getRotationMatrix2D(center, 0, 0.7)\n",
    "    scale_up = cv2.warpAffine(img_np, M_scale_up, (w, h), borderValue=255)\n",
    "    scale_down = cv2.warpAffine(img_np, M_scale_down, (w, h), borderValue=255)\n",
    "    \n",
    "    # Shearing\n",
    "    pts1 = np.float32([[0, 0], [w, 0], [0, h]])\n",
    "    # Shear X\n",
    "    pts2_x = np.float32([[0, 0], [w, h//4], [0, h]])\n",
    "    M_shear_x = cv2.getAffineTransform(pts1, pts2_x)\n",
    "    shear_x = cv2.warpAffine(img_np, M_shear_x, (w, h), borderValue=255)\n",
    "    # Shear Y\n",
    "    pts2_y = np.float32([[w//4, 0], [w, 0], [0, h]])\n",
    "    M_shear_y = cv2.getAffineTransform(pts1, pts2_y)\n",
    "    shear_y = cv2.warpAffine(img_np, M_shear_y, (w, h), borderValue=255)\n",
    "    \n",
    "    # Perspective transformation\n",
    "    pts1 = np.float32([[0, 0], [w, 0], [0, h], [w, h]])\n",
    "    pts2 = np.float32([[0, 0], [w, 0], [w//4, h], [3*w//4, h]])\n",
    "    M_persp = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    perspective = cv2.warpPerspective(img_np, M_persp, (w, h), borderValue=255)\n",
    "    \n",
    "    # Store transformations\n",
    "    transformations = {\n",
    "        'Original': img_np,\n",
    "        'Translate Right': trans_right,\n",
    "        'Translate Down': trans_down,\n",
    "        'Rotate 15°': rot15,\n",
    "        'Rotate 30°': rot30,\n",
    "        'Rotate 45°': rot45,\n",
    "        'Scale Up (1.5x)': scale_up,\n",
    "        'Scale Down (0.7x)': scale_down,\n",
    "        'Shear X': shear_x,\n",
    "        'Shear Y': shear_y,\n",
    "        'Perspective': perspective\n",
    "    }\n",
    "    \n",
    "    # Display transformations\n",
    "    n_transforms = len(transformations)\n",
    "    n_cols = 4\n",
    "    n_rows = (n_transforms + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 3 * n_rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, (name, trans_img) in enumerate(transformations.items()):\n",
    "        axes[i].imshow(trans_img, cmap='gray')\n",
    "        axes[i].set_title(name)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(n_transforms, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_dir}/affine_transformations.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return transformations\n",
    "\n",
    "def visualize_transformations_on_samples(dataset, num_samples=3, save_dir=\"data_analysis/transformations\"):\n",
    "    \"\"\"Apply and visualize transformations on multiple samples from the dataset.\"\"\"\n",
    "    if dataset is None or len(dataset) == 0:\n",
    "        print(\"No dataset available for transformation visualization\")\n",
    "        return\n",
    "    \n",
    "    # Randomly select samples\n",
    "    sample_indices = random.sample(range(len(dataset)), min(num_samples, len(dataset)))\n",
    "    \n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        img, label = dataset[idx]\n",
    "        class_name = dataset.classes[label]\n",
    "        \n",
    "        print(f\"\\nSample {i+1}: Class '{class_name}'\")\n",
    "        \n",
    "        # Apply basic transformations\n",
    "        print(\"Applying basic transformations...\")\n",
    "        basic_trans = apply_basic_transformations(img, save_dir=f\"{save_dir}/sample_{i+1}_class_{class_name}\")\n",
    "        \n",
    "        # Apply affine transformations\n",
    "        print(\"Applying affine transformations...\")\n",
    "        affine_trans = apply_affine_transformations(img, save_dir=f\"{save_dir}/sample_{i+1}_class_{class_name}\")\n",
    "\n",
    "# Example usage (commented out)\n",
    "\"\"\"\n",
    "# Visualize transformations on sample images\n",
    "visualize_transformations_on_samples(dataset, num_samples=3)\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f094a496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 5: Data Augmentation Experiments ---\n",
    "\"\"\"\n",
    "## Data Augmentation Experiments\n",
    "\n",
    "Explore various data augmentation techniques for handwritten character recognition:\n",
    "- Comparing different augmentation strategies\n",
    "- Visualizing augmented samples\n",
    "- Creating custom augmentation pipelines\n",
    "\"\"\"\n",
    "\n",
    "def visualize_augmentation_techniques(img, save_dir=\"data_analysis/augmentations\"):\n",
    "    \"\"\"Visualize different augmentation techniques on a single image.\"\"\"\n",
    "    if img is None:\n",
    "        print(\"No image provided for augmentation\")\n",
    "        return\n",
    "    \n",
    "    # Convert to PIL image if needed\n",
    "    if not isinstance(img, Image.Image):\n",
    "        img = Image.fromarray(img)\n",
    "    \n",
    "    # Ensure grayscale\n",
    "    img_gray = img.convert('L')\n",
    "    \n",
    "    # Basic augmentations\n",
    "    basic_transforms = {\n",
    "        'Original': transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.ToPILImage()\n",
    "        ]),\n",
    "        'RandomRotation(±30°)': transforms.Compose([\n",
    "            transforms.RandomRotation(30, fill=255),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.ToPILImage()\n",
    "        ]),\n",
    "        'RandomAffine': transforms.Compose([\n",
    "            transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10, fill=255),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.ToPILImage()\n",
    "        ]),\n",
    "        'ColorJitter': transforms.Compose([\n",
    "            transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.ToPILImage()\n",
    "        ]),\n",
    "        'GaussianBlur': transforms.Compose([\n",
    "            transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.ToPILImage()\n",
    "        ]),\n",
    "        'RandomPerspective': transforms.Compose([\n",
    "            transforms.RandomPerspective(distortion_scale=0.3, p=1.0, fill=255),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.ToPILImage()\n",
    "        ]),\n",
    "        'Thickness': ThicknessTransform(kernel_range=(1, 3), p=1.0)\n",
    "    }\n",
    "    \n",
    "    # Custom augmentation pipelines\n",
    "    custom_pipelines = {\n",
    "        'Light Augmentation': create_custom_transforms('light'),\n",
    "        'Medium Augmentation': create_custom_transforms('medium'),\n",
    "        'Heavy Augmentation': create_custom_transforms('heavy')\n",
    "    }\n",
    "    \n",
    "    # Apply basic transformations\n",
    "    basic_results = {}\n",
    "    for name, transform in basic_transforms.items():\n",
    "        basic_results[name] = transform(img_gray)\n",
    "    \n",
    "    # Apply pipelines (need to convert back from tensor)\n",
    "    pipeline_results = {}\n",
    "    for name, pipeline in custom_pipelines.items():\n",
    "        # Apply multiple times to show variation\n",
    "        pipeline_results[name] = []\n",
    "        for _ in range(3):\n",
    "            tensor = pipeline(img_gray)\n",
    "            # Convert tensor to PIL image\n",
    "            img_aug = transforms.ToPILImage()(torch.clamp(tensor, 0, 1))\n",
    "            pipeline_results[name].append(img_aug)\n",
    "    \n",
    "    # Visualize basic augmentations\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Basic augmentations\n",
    "    for i, (name, img_aug) in enumerate(basic_results.items()):\n",
    "        plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(img_aug, cmap='gray')\n",
    "        plt.title(name)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_dir}/basic_augmentations.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Visualize pipeline augmentations\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    row = 0\n",
    "    for name, img_list in pipeline_results.items():\n",
    "        for i, img_aug in enumerate(img_list):\n",
    "            plt.subplot(3, 3, row*3 + i + 1)\n",
    "            \n",
    "            # Convert tensor to numpy for display\n",
    "            plt.imshow(img_aug, cmap='gray')\n",
    "            plt.title(f\"{name} (Sample {i+1})\")\n",
    "            plt.axis('off')\n",
    "        row += 1\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_dir}/pipeline_augmentations.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return basic_results, pipeline_results\n",
    "\n",
    "def create_augmentation_grid(img, n_samples=10, transform=None, save_path=None):\n",
    "    \"\"\"Create a grid of augmented samples using a single transform.\"\"\"\n",
    "    if img is None:\n",
    "        print(\"No image provided for augmentation grid\")\n",
    "        return\n",
    "    \n",
    "    if transform is None:\n",
    "        print(\"No transform provided for augmentation grid\")\n",
    "        return\n",
    "    \n",
    "    # Convert to PIL image if needed\n",
    "    if not isinstance(img, Image.Image):\n",
    "        img = Image.fromarray(img)\n",
    "    \n",
    "    # Apply the transform multiple times\n",
    "    samples = []\n",
    "    for _ in range(n_samples):\n",
    "        try:\n",
    "            aug_img = transform(img)\n",
    "            \n",
    "            # If it's a tensor, convert back to PIL\n",
    "            if isinstance(aug_img, torch.Tensor):\n",
    "                aug_img = transforms.ToPILImage()(torch.clamp(aug_img, 0, 1))\n",
    "                \n",
    "            samples.append(aug_img)\n",
    "        except Exception as e:\n",
    "            print(f\"Error applying transform: {e}\")\n",
    "    \n",
    "    # Create grid\n",
    "    rows = int(np.ceil(np.sqrt(n_samples)))\n",
    "    cols = int(np.ceil(n_samples / rows))\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols*2, rows*2))\n",
    "    axes = axes.flatten() if isinstance(axes, np.ndarray) else [axes]\n",
    "    \n",
    "    # Add original image as first\n",
    "    axes[0].imshow(img, cmap='gray')\n",
    "    axes[0].set_title(\"Original\")\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Add augmented samples\n",
    "    for i, sample in enumerate(samples):\n",
    "        if i+1 < len(axes):\n",
    "            axes[i+1].imshow(sample, cmap='gray')\n",
    "            axes[i+1].set_title(f\"Aug {i+1}\")\n",
    "            axes[i+1].axis('off')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(n_samples+1, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    return samples\n",
    "\n",
    "def compare_augmentation_strategies(dataset, save_dir=\"data_analysis/augmentations\"):\n",
    "    \"\"\"Compare different augmentation strategies on dataset samples.\"\"\"\n",
    "    if dataset is None or len(dataset) == 0:\n",
    "        print(\"No dataset available for augmentation comparison\")\n",
    "        return\n",
    "    \n",
    "    # Define augmentation strategies\n",
    "    strategies = {\n",
    "        'Light': create_custom_transforms('light'),\n",
    "        'Medium': create_custom_transforms('medium'),\n",
    "        'Heavy': create_custom_transforms('heavy'),\n",
    "        'Rotation-focused': transforms.Compose([\n",
    "            transforms.Resize((64, 64)),\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.RandomRotation(30, fill=255),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: x.repeat(3, 1, 1) if x.size(0) == 1 else x),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'Distortion-focused': transforms.Compose([\n",
    "            transforms.Resize((64, 64)),\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.RandomPerspective(distortion_scale=0.4, p=0.7, fill=255),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.8, 1.2), shear=15, fill=255),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: x.repeat(3, 1, 1) if x.size(0) == 1 else x),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'Noise-focused': transforms.Compose([\n",
    "            transforms.Resize((64, 64)),\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0)),\n",
    "            transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: x.repeat(3, 1, 1) if x.size(0) == 1 else x),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'Custom-Thickness': transforms.Compose([\n",
    "            transforms.Resize((64, 64)),\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            ThicknessTransform(kernel_range=(1, 3), p=0.7),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: x.repeat(3, 1, 1) if x.size(0) == 1 else x),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    }\n",
    "    \n",
    "    # Select a few samples\n",
    "    sample_indices = random.sample(range(len(dataset)), min(3, len(dataset)))\n",
    "    \n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        img, label = dataset[idx]\n",
    "        class_name = dataset.classes[label]\n",
    "        \n",
    "        print(f\"\\nSample {i+1}: Class '{class_name}'\")\n",
    "        \n",
    "        # Create a directory for this sample\n",
    "        sample_dir = f\"{save_dir}/sample_{i+1}_class_{class_name}\"\n",
    "        os.makedirs(sample_dir, exist_ok=True)\n",
    "        \n",
    "        # Apply each strategy\n",
    "        for name, strategy in strategies.items():\n",
    "            print(f\"Applying {name} augmentation strategy...\")\n",
    "            save_path = f\"{sample_dir}/{name}_strategy.png\"\n",
    "            create_augmentation_grid(img, n_samples=9, transform=strategy, save_path=save_path)\n",
    "    \n",
    "    # Compare and analyze augmentation diversity across strategies\n",
    "    # (Advanced analysis could be added here)\n",
    "    \n",
    "    return strategies\n",
    "\n",
    "# Example usage (commented out)\n",
    "\"\"\"\n",
    "# Visualize augmentation techniques on a sample image\n",
    "sample_idx = random.randint(0, len(dataset)-1)\n",
    "sample_img, _ = dataset[sample_idx]\n",
    "basic_augs, pipeline_augs = visualize_augmentation_techniques(sample_img)\n",
    "\n",
    "# Compare different augmentation strategies\n",
    "augmentation_strategies = compare_augmentation_strategies(dataset)\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de2ea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 6: Preprocessing and Normalization ---\n",
    "\"\"\"\n",
    "## Preprocessing and Normalization\n",
    "\n",
    "Explore preprocessing and normalization techniques for handwritten character recognition:\n",
    "- Noise removal\n",
    "- Thresholding and binarization methods\n",
    "- Normalization approaches\n",
    "- Character extraction and segmentation\n",
    "\"\"\"\n",
    "\n",
    "def explore_preprocessing_techniques(img, save_dir=\"data_analysis/transformations\"):\n",
    "    \"\"\"Explore various preprocessing techniques for handwritten character recognition.\"\"\"\n",
    "    if img is None:\n",
    "        print(\"No image provided for preprocessing\")\n",
    "        return\n",
    "    \n",
    "    # Convert to PIL image if needed\n",
    "    if not isinstance(img, Image.Image):\n",
    "        img = Image.fromarray(img)\n",
    "    \n",
    "    # Ensure grayscale\n",
    "    img_gray = img.convert('L')\n",
    "    img_np = np.array(img_gray)\n",
    "    \n",
    "    # Basic preprocessing\n",
    "    # 1. Noise removal\n",
    "    blur = cv2.GaussianBlur(img_np, (3, 3), 0)\n",
    "    median = cv2.medianBlur(img_np, 3)\n",
    "    bilateral = cv2.bilateralFilter(img_np, 9, 75, 75)\n",
    "    \n",
    "    # 2. Thresholding\n",
    "    _, binary_global = cv2.threshold(img_np, 127, 255, cv2.THRESH_BINARY)\n",
    "    _, binary_otsu = cv2.threshold(img_np, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    binary_adaptive = cv2.adaptiveThreshold(img_np, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                          cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    # 3. Edge detection\n",
    "    edges_sobel_x = cv2.Sobel(img_np, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    edges_sobel_y = cv2.Sobel(img_np, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    edges_sobel = cv2.magnitude(edges_sobel_x, edges_sobel_y)\n",
    "    edges_sobel = cv2.normalize(edges_sobel, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    \n",
    "    edges_canny = cv2.Canny(img_np, 100, 200)\n",
    "    \n",
    "    # 4. Morphological operations\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    erosion = cv2.erode(binary_otsu, kernel, iterations=1)\n",
    "    dilation = cv2.dilate(binary_otsu, kernel, iterations=1)\n",
    "    opening = cv2.morphologyEx(binary_otsu, cv2.MORPH_OPEN, kernel)\n",
    "    closing = cv2.morphologyEx(binary_otsu, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # 5. Skeletonization\n",
    "    # Using distance transform and threshold for a simple skeleton approximation\n",
    "    dist_transform = cv2.distanceTransform(binary_otsu, cv2.DIST_L2, 5)\n",
    "    dist_transform = cv2.normalize(dist_transform, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    _, skeleton_approx = cv2.threshold(dist_transform, 50, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Combine preprocessing steps\n",
    "    # Clean -> Binarize -> Thin\n",
    "    clean_binary_thin = cv2.erode(binary_adaptive, kernel, iterations=1)\n",
    "    \n",
    "    # Create a dictionary of all preprocessing results\n",
    "    preprocessing = {\n",
    "        'Original': img_np,\n",
    "        'Gaussian Blur': blur,\n",
    "        'Median Blur': median,\n",
    "        'Bilateral Filter': bilateral,\n",
    "        'Global Threshold': binary_global,\n",
    "        'Otsu Threshold': binary_otsu,\n",
    "        'Adaptive Threshold': binary_adaptive,\n",
    "        'Sobel Edges': edges_sobel,\n",
    "        'Canny Edges': edges_canny,\n",
    "        'Erosion': erosion,\n",
    "        'Dilation': dilation,\n",
    "        'Opening': opening,\n",
    "        'Closing': closing,\n",
    "        'Skeleton Approximation': skeleton_approx,\n",
    "        'Clean+Binary+Thin': clean_binary_thin\n",
    "    }\n",
    "    \n",
    "    # Display preprocessing results\n",
    "    n_preproc = len(preprocessing)\n",
    "    n_cols = 4\n",
    "    n_rows = (n_preproc + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 3 * n_rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, (name, proc_img) in enumerate(preprocessing.items()):\n",
    "        axes[i].imshow(proc_img, cmap='gray')\n",
    "        axes[i].set_title(name)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(n_preproc, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_dir}/preprocessing_techniques.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return preprocessing\n",
    "\n",
    "def explore_normalization_methods(img, save_dir=\"data_analysis/transformations\"):\n",
    "    \"\"\"Explore different normalization methods for neural network inputs.\"\"\"\n",
    "    if img is None:\n",
    "        print(\"No image provided for normalization\")\n",
    "        return\n",
    "    \n",
    "    # Convert to PIL image if needed\n",
    "    if not isinstance(img, Image.Image):\n",
    "        img = Image.fromarray(img)\n",
    "    \n",
    "    # Ensure grayscale\n",
    "    img_gray = img.convert('L')\n",
    "    \n",
    "    # Resize to common input size for neural networks\n",
    "    img_resized = img_gray.resize((64, 64), Image.LANCZOS)\n",
    "    img_np = np.array(img_resized)\n",
    "    \n",
    "    # Normalization methods\n",
    "    # 1. Simple rescaling to [0, 1]\n",
    "    norm_01 = img_np / 255.0\n",
    "    \n",
    "    # 2. Rescaling to [-1, 1]\n",
    "    norm_11 = 2 * (img_np / 255.0) - 1\n",
    "    \n",
    "    # 3. Standard normalization (zero mean, unit variance)\n",
    "    mean = np.mean(img_np)\n",
    "    std = np.std(img_np)\n",
    "    norm_std = (img_np - mean) / (std if std > 0 else 1)\n",
    "    \n",
    "    # 4. Min-max normalization\n",
    "    min_val = np.min(img_np)\n",
    "    max_val = np.max(img_np)\n",
    "    norm_minmax = (img_np - min_val) / (max_val - min_val if max_val > min_val else 1)\n",
    "    \n",
    "    # 5. ImageNet normalization (common for transfer learning)\n",
    "    # First, convert to RGB (3 channels)\n",
    "    img_rgb = np.stack([img_np, img_np, img_np], axis=2) / 255.0\n",
    "    imagenet_mean = np.array([0.485, 0.456, 0.406])\n",
    "    imagenet_std = np.array([0.229, 0.224, 0.225])\n",
    "    norm_imagenet = (img_rgb - imagenet_mean) / imagenet_std\n",
    "    \n",
    "    # Convert single channel back for visualization\n",
    "    norm_imagenet_vis = norm_imagenet[:, :, 0]\n",
    "    \n",
    "    # Visualize normalization methods\n",
    "    normalizations = {\n",
    "        'Original': img_np,\n",
    "        'Rescaled [0, 1]': norm_01,\n",
    "        'Rescaled [-1, 1]': norm_11,\n",
    "        'Standardized': norm_std,\n",
    "        'Min-Max': norm_minmax,\n",
    "        'ImageNet': norm_imagenet_vis\n",
    "    }\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, (name, norm_img) in enumerate(normalizations.items()):\n",
    "        # Use imshow with appropriate vmin/vmax\n",
    "        if name == 'Original':\n",
    "            axes[i].imshow(norm_img, cmap='gray')\n",
    "        else:\n",
    "            # For the normalized images, use full range colormap\n",
    "            vmin = np.min(norm_img)\n",
    "            vmax = np.max(norm_img)\n",
    "            img_display = axes[i].imshow(norm_img, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "            \n",
    "            # Add colorbar\n",
    "            plt.colorbar(img_display, ax=axes[i], fraction=0.046, pad=0.04)\n",
    "            \n",
    "            # Add min/max annotations\n",
    "            axes[i].text(0.05, 0.95, f\"Min: {vmin:.2f}\", transform=axes[i].transAxes, \n",
    "                       fontsize=8, verticalalignment='top', color='red')\n",
    "            axes[i].text(0.05, 0.90, f\"Max: {vmax:.2f}\", transform=axes[i].transAxes, \n",
    "                       fontsize=8, verticalalignment='top', color='red')\n",
    "        \n",
    "        axes[i].set_title(name)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_dir}/normalization_methods.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return normalizations\n",
    "\n",
    "def character_segmentation_demo(img, save_dir=\"data_analysis/transformations\"):\n",
    "    \"\"\"Demonstrate character segmentation from an image with multiple characters.\"\"\"\n",
    "    if img is None:\n",
    "        print(\"No image provided for segmentation\")\n",
    "        return\n",
    "    \n",
    "    # Convert to PIL image if needed\n",
    "    if not isinstance(img, Image.Image):\n",
    "        img = Image.fromarray(img)\n",
    "    \n",
    "    # Ensure grayscale\n",
    "    img_gray = img.convert('L')\n",
    "    img_np = np.array(img_gray)\n",
    "    \n",
    "    # Preprocessing for segmentation\n",
    "    # 1. Binarization\n",
    "    _, binary = cv2.threshold(img_np, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # 2. Noise removal\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    # 3. Find contours\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # 4. Filter contours by size\n",
    "    min_area = 50\n",
    "    valid_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > min_area]\n",
    "    \n",
    "    # 5. Sort contours from left to right\n",
    "    valid_contours = sorted(valid_contours, key=lambda cnt: cv2.boundingRect(cnt)[0])\n",
    "    \n",
    "    # Prepare visualization\n",
    "    # Original image with contours\n",
    "    contour_img = cv2.cvtColor(img_np, cv2.COLOR_GRAY2RGB)\n",
    "    cv2.drawContours(contour_img, valid_contours, -1, (0, 255, 0), 2)\n",
    "    \n",
    "    # Original image with bounding boxes\n",
    "    bbox_img = cv2.cvtColor(img_np, cv2.COLOR_GRAY2RGB)\n",
    "    for i, cnt in enumerate(valid_contours):\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        cv2.rectangle(bbox_img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "        cv2.putText(bbox_img, str(i+1), (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "    \n",
    "    # Extract and normalize individual characters\n",
    "    extracted_chars = []\n",
    "    normalized_chars = []\n",
    "    \n",
    "    for i, cnt in enumerate(valid_contours):\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        \n",
    "        # Extract character\n",
    "        char_img = img_np[y:y+h, x:x+w]\n",
    "        extracted_chars.append(char_img)\n",
    "        \n",
    "        # Normalize character (resize to fixed size with padding)\n",
    "        # Create a padded image with white background\n",
    "        padding = 10  # Pixels of padding around the character\n",
    "        target_size = 64\n",
    "        \n",
    "        # Resize while maintaining aspect ratio\n",
    "        if w > h:\n",
    "            new_w = target_size - 2*padding\n",
    "            new_h = int(h * new_w / w)\n",
    "        else:\n",
    "            new_h = target_size - 2*padding\n",
    "            new_w = int(w * new_h / h)\n",
    "        \n",
    "        resized = cv2.resize(char_img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        # Create padded image\n",
    "        padded = np.ones((target_size, target_size), dtype=np.uint8) * 255\n",
    "        \n",
    "        # Calculate position to paste the resized image\n",
    "        x_offset = (target_size - new_w) // 2\n",
    "        y_offset = (target_size - new_h) // 2\n",
    "        \n",
    "        # Paste the resized image\n",
    "        padded[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized\n",
    "        \n",
    "        normalized_chars.append(padded)\n",
    "    \n",
    "    # Visualize the segmentation process\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Original image\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(img_np, cmap='gray')\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Binary image\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.imshow(binary, cmap='gray')\n",
    "    plt.title(\"Binary Image\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Contours\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.imshow(contour_img)\n",
    "    plt.title(f\"Contours ({len(valid_contours)} found)\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Bounding boxes\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(bbox_img)\n",
    "    plt.title(\"Bounding Boxes\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_dir}/segmentation_process.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Visualize extracted and normalized characters\n",
    "    if extracted_chars:\n",
    "        n_chars = len(extracted_chars)\n",
    "        \n",
    "        plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        # Extracted characters\n",
    "        for i, char_img in enumerate(extracted_chars):\n",
    "            plt.subplot(2, n_chars, i+1)\n",
    "            plt.imshow(char_img, cmap='gray')\n",
    "            plt.title(f\"Extracted {i+1}\")\n",
    "            plt.axis('off')\n",
    "        \n",
    "        # Normalized characters\n",
    "        for i, char_img in enumerate(normalized_chars):\n",
    "            plt.subplot(2, n_chars, n_chars+i+1)\n",
    "            plt.imshow(char_img, cmap='gray')\n",
    "            plt.title(f\"Normalized {i+1}\")\n",
    "            plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{save_dir}/extracted_characters.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    return {\n",
    "        'binary': binary,\n",
    "        'contours': valid_contours,\n",
    "        'extracted': extracted_chars,\n",
    "        'normalized': normalized_chars\n",
    "    }\n",
    "\n",
    "# Example usage (commented out)\n",
    "\"\"\"\n",
    "# Get a sample image from the dataset\n",
    "sample_idx = random.randint(0, len(dataset)-1)\n",
    "sample_img, _ = dataset[sample_idx]\n",
    "\n",
    "# Explore preprocessing techniques\n",
    "preproc_results = explore_preprocessing_techniques(sample_img)\n",
    "\n",
    "# Explore normalization methods\n",
    "norm_results = explore_normalization_methods(sample_img)\n",
    "\n",
    "# Demonstrate character segmentation\n",
    "# Note: This requires an image with multiple characters\n",
    "# sample_text_img = Image.open(\"path/to/handwritten_text.png\")\n",
    "# segmentation_results = character_segmentation_demo(sample_text_img)\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a79ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 7: Complete Data Analysis Pipeline ---\n",
    "\"\"\"\n",
    "## Complete Data Analysis Pipeline\n",
    "\n",
    "This section combines the previous analyses into a comprehensive pipeline for dataset exploration.\n",
    "It demonstrates the complete process from data loading to preprocessing and augmentation.\n",
    "\"\"\"\n",
    "\n",
    "def run_complete_data_analysis(data_root, save_dir=\"data_analysis\"):\n",
    "    \"\"\"\n",
    "    Run a complete data analysis pipeline on the handwritten character dataset.\n",
    "    \n",
    "    Args:\n",
    "        data_root: Path to the dataset root directory\n",
    "        save_dir: Directory to save analysis results\n",
    "    \"\"\"\n",
    "    print(f\"Running complete data analysis pipeline on: {data_root}\")\n",
    "    \n",
    "    # Step 1: Load and explore dataset\n",
    "    print(\"\\nStep 1: Loading and exploring dataset...\")\n",
    "    dataset, class_names, stats = load_and_explore_dataset(data_root)\n",
    "    \n",
    "    if dataset is None:\n",
    "        print(\"Failed to load dataset. Aborting analysis.\")\n",
    "        return None\n",
    "    \n",
    "    # Step 2: Visualize class distribution\n",
    "    print(\"\\nStep 2: Visualizing class distribution...\")\n",
    "    visualize_class_distribution(stats, save_path=f\"{save_dir}/statistics/class_distribution.png\")\n",
    "    \n",
    "    # Step 3: Visualize sample images\n",
    "    print(\"\\nStep 3: Visualizing sample images...\")\n",
    "    visualize_sample_images(dataset, num_classes=min(10, len(class_names)), samples_per_class=5, \n",
    "                         save_path=f\"{save_dir}/statistics/sample_images.png\")\n",
    "    \n",
    "    # Step 4: Analyze image properties\n",
    "    print(\"\\nStep 4: Analyzing image properties...\")\n",
    "    image_properties = analyze_image_properties(dataset, sample_size=100, save_dir=f\"{save_dir}/statistics\")\n",
    "    \n",
    "    # Step 5: Extract stroke features\n",
    "    print(\"\\nStep 5: Extracting stroke features...\")\n",
    "    stroke_features = extract_stroke_features(dataset, sample_size=20, save_dir=f\"{save_dir}/statistics\")\n",
    "    \n",
    "    # Step 6: Visualize transformations on sample images\n",
    "    print(\"\\nStep 6: Visualizing transformations on sample images...\")\n",
    "    # Select a few samples for transformation visualization\n",
    "    sample_indices = random.sample(range(len(dataset)), 2)\n",
    "    \n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        img, label = dataset[idx]\n",
    "        class_name = dataset.classes[label]\n",
    "        \n",
    "        print(f\"  Sample {i+1}: Class '{class_name}'\")\n",
    "        \n",
    "        # Apply and visualize basic transformations\n",
    "        basic_trans = apply_basic_transformations(\n",
    "            img, save_dir=f\"{save_dir}/transformations/sample_{i+1}_class_{class_name}\"\n",
    "        )\n",
    "        \n",
    "        # Apply and visualize affine transformations\n",
    "        affine_trans = apply_affine_transformations(\n",
    "            img, save_dir=f\"{save_dir}/transformations/sample_{i+1}_class_{class_name}\"\n",
    "        )\n",
    "    \n",
    "    # Step 7: Visualize augmentation techniques\n",
    "    print(\"\\nStep 7: Visualizing augmentation techniques...\")\n",
    "    # Select a sample for augmentation visualization\n",
    "    aug_idx = random.randint(0, len(dataset)-1)\n",
    "    aug_img, aug_label = dataset[aug_idx]\n",
    "    aug_class = dataset.classes[aug_label]\n",
    "    \n",
    "    print(f\"  Using sample from class '{aug_class}'\")\n",
    "    basic_augs, pipeline_augs = visualize_augmentation_techniques(\n",
    "        aug_img, save_dir=f\"{save_dir}/augmentations/class_{aug_class}\"\n",
    "    )\n",
    "    \n",
    "    # Step 8: Explore preprocessing techniques\n",
    "    print(\"\\nStep 8: Exploring preprocessing techniques...\")\n",
    "    preproc_results = explore_preprocessing_techniques(\n",
    "        aug_img, save_dir=f\"{save_dir}/transformations/class_{aug_class}\"\n",
    "    )\n",
    "    \n",
    "    # Step 9: Explore normalization methods\n",
    "    print(\"\\nStep 9: Exploring normalization methods...\")\n",
    "    norm_results = explore_normalization_methods(\n",
    "        aug_img, save_dir=f\"{save_dir}/transformations/class_{aug_class}\"\n",
    "    )\n",
    "    \n",
    "    # Step 10: Generate summary report\n",
    "    print(\"\\nStep 10: Generating summary report...\")\n",
    "    with open(f\"{save_dir}/data_analysis_summary.txt\", 'w') as f:\n",
    "        f.write(\"# Handwritten Character Recognition Dataset Analysis\\n\\n\")\n",
    "        \n",
    "        f.write(\"## Dataset Summary\\n\")\n",
    "        f.write(f\"- Dataset path: {data_root}\\n\")\n",
    "        f.write(f\"- Total samples: {stats['total_samples']}\\n\")\n",
    "        f.write(f\"- Number of classes: {stats['num_classes']}\\n\")\n",
    "        f.write(f\"- Min samples per class: {stats['min_samples_per_class']}\\n\")\n",
    "        f.write(f\"- Max samples per class: {stats['max_samples_per_class']}\\n\")\n",
    "        f.write(f\"- Avg samples per class: {stats['avg_samples_per_class']:.2f}\\n\\n\")\n",
    "        \n",
    "        f.write(\"## Image Properties\\n\")\n",
    "        if image_properties:\n",
    "            f.write(f\"- Width (pixels): mean={image_properties['width']['mean']:.2f}, std={image_properties['width']['std']:.2f}\\n\")\n",
    "            f.write(f\"- Height (pixels): mean={image_properties['height']['mean']:.2f}, std={image_properties['height']['std']:.2f}\\n\")\n",
    "            f.write(f\"- Aspect Ratio (w/h): mean={image_properties['aspect_ratio']['mean']:.2f}, std={image_properties['aspect_ratio']['std']:.2f}\\n\")\n",
    "            f.write(f\"- Mean Intensity: mean={image_properties['mean_intensity']['mean']:.2f}, std={image_properties['mean_intensity']['std']:.2f}\\n\\n\")\n",
    "        \n",
    "        f.write(\"## Stroke Features\\n\")\n",
    "        if stroke_features:\n",
    "            f.write(f\"- Max Stroke Thickness: mean={stroke_features['stroke_thickness']['mean']:.2f} pixels, std={stroke_features['stroke_thickness']['std']:.2f}\\n\")\n",
    "            f.write(f\"- Number of Contours: mean={stroke_features['stroke_continuity']['mean']:.2f}, std={stroke_features['stroke_continuity']['std']:.2f}\\n\")\n",
    "            f.write(f\"- Character Density: mean={stroke_features['character_density']['mean']:.2f}, std={stroke_features['character_density']['std']:.2f}\\n\\n\")\n",
    "        \n",
    "        f.write(\"## Analysis Results\\n\")\n",
    "        f.write(\"- The dataset has been analyzed for various properties and characteristics.\\n\")\n",
    "        f.write(\"- Visualizations of transformations, augmentations, and preprocessing techniques have been generated.\\n\")\n",
    "        f.write(\"- Refer to the individual image files in the analysis directory for detailed visualizations.\\n\")\n",
    "    \n",
    "    print(f\"\\nData analysis complete. Results saved to {save_dir}\")\n",
    "    return {\n",
    "        'dataset': dataset,\n",
    "        'class_names': class_names,\n",
    "        'stats': stats,\n",
    "        'image_properties': image_properties,\n",
    "        'stroke_features': stroke_features\n",
    "    }\n",
    "\n",
    "# Example usage (commented out)\n",
    "\"\"\"\n",
    "# Specify your dataset path\n",
    "DATA_ROOT = \"./datasets/handwritten-english/augmented_images1\"\n",
    "\n",
    "# Run the complete data analysis pipeline\n",
    "analysis_results = run_complete_data_analysis(DATA_ROOT)\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98c2011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 8: Run Data Analysis (User Code) ---\n",
    "\"\"\"\n",
    "## Run Data Analysis\n",
    "\n",
    "This is where you run the actual data analysis pipeline with your dataset.\n",
    "Uncomment and modify the code below to analyze your own dataset.\n",
    "\"\"\"\n",
    "\n",
    "# Define your dataset path\n",
    "# DATA_ROOT = \"./datasets/handwritten-english/augmented_images1\"\n",
    "\n",
    "# Option 1: Run the complete data analysis pipeline\n",
    "\"\"\"\n",
    "analysis_results = run_complete_data_analysis(DATA_ROOT)\n",
    "\"\"\"\n",
    "\n",
    "# Option 2: Run specific analyses\n",
    "\"\"\"\n",
    "# Load and explore the dataset\n",
    "dataset, class_names, stats = load_and_explore_dataset(DATA_ROOT)\n",
    "\n",
    "# Visualize class distribution\n",
    "visualize_class_distribution(stats)\n",
    "\n",
    "# Analyze image properties\n",
    "image_properties = analyze_image_properties(dataset, sample_size=100)\n",
    "\n",
    "# Extract and analyze stroke features\n",
    "stroke_features = extract_stroke_features(dataset, sample_size=20)\n",
    "\n",
    "# Select a sample image for detailed analysis\n",
    "sample_idx = random.randint(0, len(dataset)-1)\n",
    "sample_img, sample_label = dataset[sample_idx]\n",
    "sample_class = dataset.classes[sample_label]\n",
    "print(f\"Selected sample from class '{sample_class}'\")\n",
    "\n",
    "# Visualize transformations\n",
    "basic_trans = apply_basic_transformations(sample_img)\n",
    "affine_trans = apply_affine_transformations(sample_img)\n",
    "\n",
    "# Visualize augmentation techniques\n",
    "basic_augs, pipeline_augs = visualize_augmentation_techniques(sample_img)\n",
    "\n",
    "# Explore preprocessing techniques\n",
    "preproc_results = explore_preprocessing_techniques(sample_img)\n",
    "\n",
    "# Explore normalization methods\n",
    "norm_results = explore_normalization_methods(sample_img)\n",
    "\"\"\"\n",
    "\n",
    "# Option 3: Character segmentation demo\n",
    "\"\"\"\n",
    "# Load a sample multi-character image\n",
    "# This requires an image with multiple characters\n",
    "# sample_text_img = Image.open(\"path/to/handwritten_text.png\")\n",
    "# segmentation_results = character_segmentation_demo(sample_text_img)\n",
    "\"\"\"\n",
    "\n",
    "print(\"This notebook is ready for data analysis of handwritten character recognition datasets.\")\n",
    "print(\"Uncomment one of the analysis options above and run this cell to start the analysis.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
