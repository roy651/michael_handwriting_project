{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten Character Recognition - Model Training\n",
    "\n",
    "This notebook focuses on the training aspects of a handwritten character recognition system using PyTorch. It covers:\n",
    "- Setting up the data pipeline with image loading and augmentations.\n",
    "- Defining various Convolutional Neural Network (CNN) architectures, including custom CNNs and a VGG19-based transfer learning model.\n",
    "- Utility functions for the training loop, model saving/loading, and evaluation.\n",
    "- Conducting training experiments for the defined models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General utilities\n",
    "import os\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "\n",
    "# Image processing and display\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2 # OpenCV for image operations\n",
    "import numpy as np\n",
    "\n",
    "# PyTorch essentials\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "# For dataset path handling (if needed)\n",
    "from pathlib import Path\n",
    "\n",
    "# Note: Kaggle API setup and dataset download cells from the consolidated notebook are omitted here.\n",
    "# Users are expected to have the dataset available locally. \n",
    "# The 'data_root_example' variable in the experiment sections should be updated to the dataset path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Device Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# In a Jupyter Notebook, multiprocessing start method handling is less critical \n",
    "# than in standalone scripts, especially if not using num_workers > 0 in DataLoader\n",
    "# or if issues arise. If needed, it can be set.\n",
    "# try:\n",
    "#     torch.multiprocessing.set_start_method('spawn', force=True)\n",
    "#     print(\"Set multiprocessing start method to 'spawn'.\")\n",
    "# except RuntimeError as e:\n",
    "#     print(f\"Note: {e}. Multiprocessing start method might have been already set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Custom Data Augmentation Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomChoice(torch.nn.Module):\n",
    "    \"\"\"Randomly applies one of the given transforms with given probability\"\"\"\n",
    "    def __init__(self, transforms, p=0.5):\n",
    "        super().__init__()\n",
    "        self.transforms = transforms\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.p:\n",
    "            transform = random.choice(self.transforms)\n",
    "            return transform(img)\n",
    "        return img\n",
    "\n",
    "class ThicknessTransform(torch.nn.Module):\n",
    "    \"\"\"Apply morphological operations to change stroke thickness.\n",
    "    It randomly chooses between dilation (thicker) or erosion (thinner).\n",
    "    Args:\n",
    "        kernel_size (int): Size of the kernel for morphological operations (default: 3).\n",
    "        iterations (int): Number of times to apply the operation (default: 1).\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size=3, iterations=1):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.iterations = iterations\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img_cv = np.array(img)\n",
    "        if len(img_cv.shape) == 3 and img_cv.shape[2] == 3:\n",
    "            img_cv = cv2.cvtColor(img_cv, cv2.COLOR_RGB2GRAY)\n",
    "        elif len(img_cv.shape) == 3 and img_cv.shape[2] == 1:\n",
    "             img_cv = img_cv[:, :, 0]\n",
    "        \n",
    "        kernel = np.ones((self.kernel_size, self.kernel_size), np.uint8)\n",
    "        if random.random() > 0.5:\n",
    "            processed_img = cv2.dilate(img_cv, kernel, iterations=self.iterations)\n",
    "        else:\n",
    "            processed_img = cv2.erode(img_cv, kernel, iterations=self.iterations)\n",
    "        return Image.fromarray(processed_img, mode='L')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Handwriting Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandwritingDataPipeline:\n",
    "    def __init__(self, data_root, image_size=(64, 64), batch_size=32, do_transform=True, test_split=0.15, val_split=0.15):\n",
    "        self.data_root = data_root\n",
    "        self.image_size = image_size\n",
    "        self.batch_size = batch_size\n",
    "        self.do_transform = do_transform\n",
    "        self.test_split = test_split\n",
    "        self.val_split = val_split\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        self._setup_transforms()\n",
    "        self._load_and_split_datasets()\n",
    "\n",
    "    def _setup_transforms(self):\n",
    "        if self.do_transform:\n",
    "            self.train_transform = transforms.Compose([\n",
    "                transforms.Resize(self.image_size),\n",
    "                transforms.Grayscale(num_output_channels=1),\n",
    "                RandomChoice([\n",
    "                    transforms.RandomAffine(degrees=20, translate=(0.2, 0.2), scale=(0.8, 1.2), shear=10, fill=255),\n",
    "                    transforms.RandomPerspective(distortion_scale=0.3, p=0.5, fill=255),\n",
    "                    transforms.RandomRotation(15, fill=255),\n",
    "                ], p=0.8),\n",
    "                ThicknessTransform(kernel_size=random.choice([1,2,3]), iterations=random.choice([1,2])),\n",
    "                transforms.RandomApply([\n",
    "                    transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 0.5))\n",
    "                ], p=0.3),\n",
    "                transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Lambda(lambda x: x.repeat(3, 1, 1) if x.size(0)==1 else x),\n",
    "                self.normalize,\n",
    "                transforms.RandomErasing(p=0.2, scale=(0.02, 0.03), ratio=(0.3, 3.3), value='random')\n",
    "            ])\n",
    "        else:\n",
    "            self.train_transform = transforms.Compose([\n",
    "                transforms.Resize(self.image_size),\n",
    "                transforms.Grayscale(num_output_channels=1),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Lambda(lambda x: x.repeat(3, 1, 1) if x.size(0)==1 else x),\n",
    "                self.normalize\n",
    "            ])\n",
    "\n",
    "        self.val_test_transform = transforms.Compose([\n",
    "            transforms.Resize(self.image_size),\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: x.repeat(3, 1, 1) if x.size(0)==1 else x),\n",
    "            self.normalize\n",
    "        ])\n",
    "\n",
    "    def _load_and_split_datasets(self):\n",
    "        full_dataset = datasets.ImageFolder(root=self.data_root)\n",
    "        self.class_names = full_dataset.classes\n",
    "        self.num_classes = len(self.class_names)\n",
    "\n",
    "        total_size = len(full_dataset)\n",
    "        test_size = int(total_size * self.test_split)\n",
    "        remaining_size = total_size - test_size\n",
    "        val_size = int(remaining_size * (self.val_split / (1.0 - self.test_split)))\n",
    "        train_size = remaining_size - val_size\n",
    "\n",
    "        if train_size <= 0 or val_size <=0 or test_size <=0:\n",
    "            print(f\"Warning: Dataset too small for current split ratios. Total: {total_size}\")\n",
    "            if total_size < 3:\n",
    "                train_dataset, val_dataset, test_dataset = full_dataset, full_dataset, full_dataset\n",
    "            else:\n",
    "                train_size = max(1, int(total_size * 0.7))\n",
    "                val_size = max(1, int(total_size * 0.15))\n",
    "                test_size = total_size - train_size - val_size\n",
    "                if test_size <= 0:\n",
    "                    test_size = 1\n",
    "                    val_size = total_size - train_size - test_size\n",
    "                    if val_size <=0:\n",
    "                        val_size = 1\n",
    "                        train_size = total_size - val_size - test_size\n",
    "                \n",
    "        print(f\"Attempting to split: Train={train_size}, Val={val_size}, Test={test_size}\")\n",
    "        try:\n",
    "            train_temp_dataset, test_dataset_subset = torch.utils.data.random_split(full_dataset, [train_size + val_size, test_size],\n",
    "                                                                          generator=torch.Generator().manual_seed(42))\n",
    "            train_dataset_subset, val_dataset_subset = torch.utils.data.random_split(train_temp_dataset, [train_size, val_size],\n",
    "                                                                       generator=torch.Generator().manual_seed(42))\n",
    "        except Exception as e:\n",
    "            print(f\"Error during dataset splitting: {e}. Adjusting split sizes or check dataset.\")\n",
    "            print(\"Using full dataset for train/val/test due to splitting error. THIS IS NOT RECOMMENDED FOR ACTUAL TRAINING.\")\n",
    "            train_dataset_subset, val_dataset_subset, test_dataset_subset = full_dataset, full_dataset, full_dataset\n",
    "\n",
    "        self.train_dataset = TransformedDataset(train_dataset_subset, transform=self.train_transform)\n",
    "        self.val_dataset = TransformedDataset(val_dataset_subset, transform=self.val_test_transform)\n",
    "        self.test_dataset = TransformedDataset(test_dataset_subset, transform=self.val_test_transform)\n",
    "        \n",
    "        self.sizes = {'train': len(self.train_dataset), 'val': len(self.val_dataset), 'test': len(self.test_dataset)}\n",
    "\n",
    "    def get_loaders(self, shuffle_train=True, shuffle_val=False, shuffle_test=False):\n",
    "        train_loader = DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=shuffle_train, num_workers=0)\n",
    "        val_loader = DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=shuffle_val, num_workers=0)\n",
    "        test_loader = DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=shuffle_test, num_workers=0)\n",
    "        return train_loader, val_loader, test_loader\n",
    "\n",
    "    def get_class_labels(self):\n",
    "        return self.class_names\n",
    "\n",
    "class TransformedDataset(Dataset):\n",
    "    def __init__(self, subset, transform=None):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.subset[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Display Augmented Images (Helper Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_augmented_images(data_loader, num_images=5, num_augmentations=3):\n",
    "    \"\"\"Displays original and augmented images from the train_loader.\n",
    "    Args:\n",
    "        data_loader (DataLoader): The DataLoader for the training set.\n",
    "        num_images (int): Number of unique images to display.\n",
    "        num_augmentations (int): Number of augmented versions to show per image.\n",
    "    \"\"\"\n",
    "    if data_loader is None or not hasattr(data_loader, 'dataset') or not hasattr(data_loader.dataset, 'subset') \\\n",
    "       or not hasattr(data_loader.dataset.subset, 'dataset') or not hasattr(data_loader.dataset.subset.dataset, 'class_to_idx') \\\n",
    "       or not hasattr(data_loader.dataset.subset.dataset, 'imgs'):\n",
    "        print(\"Data loader is None or not structured as expected (TransformedDataset -> Subset -> ImageFolder). Cannot display images.\")\n",
    "        print(\"Please ensure the data pipeline was initialized correctly and is feeding this function.\")\n",
    "        return\n",
    "\n",
    "    imagefolder_dataset = data_loader.dataset.subset.dataset\n",
    "    class_to_idx = imagefolder_dataset.class_to_idx\n",
    "    idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "\n",
    "    subset_indices = data_loader.dataset.subset.indices\n",
    "    if len(subset_indices) < num_images:\n",
    "        print(f\"Warning: Requested {num_images} images, but dataset only has {len(subset_indices)}. Displaying all available.\")\n",
    "        num_images = len(subset_indices)\n",
    "    \n",
    "    if num_images == 0:\n",
    "        print(\"No images to display.\")\n",
    "        return\n",
    "\n",
    "    random_subset_indices = random.sample(range(len(subset_indices)), num_images)\n",
    "    fig = plt.figure(figsize=(num_augmentations * 3, num_images * 3))\n",
    "    train_transform = data_loader.dataset.transform\n",
    "\n",
    "    for i, random_idx_in_subset in enumerate(random_subset_indices):\n",
    "        original_dataset_idx = subset_indices[random_idx_in_subset]\n",
    "        original_path, true_label_idx = imagefolder_dataset.imgs[original_dataset_idx]\n",
    "        class_name = idx_to_class[true_label_idx]\n",
    "        original_pil = Image.open(original_path)\n",
    "\n",
    "        ax = plt.subplot(num_images, num_augmentations + 1, i * (num_augmentations + 1) + 1)\n",
    "        ax.imshow(original_pil.convert(\"RGB\"))\n",
    "        ax.set_title(f'Original: {class_name}')\n",
    "        ax.axis('off')\n",
    "\n",
    "        for j in range(num_augmentations):\n",
    "            augmented_tensor = train_transform(original_pil.copy())\n",
    "            ax = plt.subplot(num_images, num_augmentations + 1, i * (num_augmentations + 1) + j + 2)\n",
    "            img_display = augmented_tensor.cpu().numpy().transpose((1, 2, 0))\n",
    "            mean = np.array([0.485, 0.456, 0.406])\n",
    "            std = np.array([0.229, 0.224, 0.225])\n",
    "            img_display = std * img_display + mean\n",
    "            img_display = np.clip(img_display, 0, 1)\n",
    "            if img_display.shape[2] == 1:\n",
    "                 plt.imshow(img_display.squeeze(), cmap='gray')\n",
    "            else:\n",
    "                 plt.imshow(img_display)\n",
    "            ax.set_title(f'Aug {j+1}: {class_name}')\n",
    "            ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Architectures\n",
    "\n",
    "This section defines the neural network models used for character recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Custom CNNs (`LetterCNN64`, `ImprovedLetterCNN`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LetterCNN64(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(LetterCNN64, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 512)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = self.pool3(self.relu3(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 8 * 8)\n",
    "        x = self.relu4(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class ImprovedLetterCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ImprovedLetterCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(256 * 4 * 4, 1024)\n",
    "        self.bn_fc1 = nn.BatchNorm1d(1024)\n",
    "        self.relu_fc1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.bn_fc2 = nn.BatchNorm1d(512)\n",
    "        self.relu_fc2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(self.relu2(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(self.relu3(self.bn3(self.conv3(x))))\n",
    "        x = self.pool4(self.relu4(self.bn4(self.conv4(x))))\n",
    "        x = x.view(-1, 256 * 4 * 4)\n",
    "        x = self.dropout1(self.relu_fc1(self.bn_fc1(self.fc1(x))))\n",
    "        x = self.dropout2(self.relu_fc2(self.bn_fc2(self.fc2(x))))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. VGG19 Transfer Learning Model (`VGG19HandwritingModel`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG19HandwritingModel(nn.Module):\n",
    "    def __init__(self, num_classes, device, pretrained=True):\n",
    "        super(VGG19HandwritingModel, self).__init__()\n",
    "        self.device = device\n",
    "        vgg19 = models.vgg19_bn(weights=models.VGG19_BN_Weights.IMAGENET1K_V1 if pretrained else None)\n",
    "        vgg19 = vgg19.to(device)\n",
    "        self.features = vgg19.features\n",
    "        if pretrained:\n",
    "            for param in self.features.parameters():\n",
    "                param.requires_grad = False\n",
    "        num_features_output = 512 * 2 * 2 \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(num_features_output, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 2048),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(2048, num_classes)\n",
    "        ).to(device)\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.classifier.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=25, save_dir='model_checkpoints'):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        print(f\"Created directory: {save_dir}\")\n",
    "        \n",
    "    start_time = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "                dataloader = train_loader\n",
    "            else:\n",
    "                model.eval()\n",
    "                dataloader = val_loader\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            total_samples = 0\n",
    "\n",
    "            if dataloader is None or len(dataloader.dataset) == 0:\n",
    "                print(f\"Skipping {phase} phase as dataloader is None or dataset is empty.\")\n",
    "                continue\n",
    "\n",
    "            for inputs, labels in dataloader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                total_samples += inputs.size(0)\n",
    "            \n",
    "            if total_samples == 0:\n",
    "                epoch_loss = 0\n",
    "                epoch_acc = 0\n",
    "            else:\n",
    "                epoch_loss = running_loss / total_samples\n",
    "                epoch_acc = running_corrects.double() / total_samples\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            if phase == 'train':\n",
    "                history['train_loss'].append(epoch_loss)\n",
    "                history['train_acc'].append(epoch_acc.item())\n",
    "            else:\n",
    "                history['val_loss'].append(epoch_loss)\n",
    "                history['val_acc'].append(epoch_acc.item())\n",
    "                if scheduler:\n",
    "                    if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                        scheduler.step(epoch_loss)\n",
    "                if epoch_acc > best_acc and total_samples > 0:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    best_epoch = epoch + 1\n",
    "                    best_model_path = os.path.join(save_dir, 'best_model.pth')\n",
    "                    torch.save({\n",
    "                        'epoch': best_epoch,\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'loss': epoch_loss,\n",
    "                        'accuracy': best_acc.item(),\n",
    "                        'scheduler_state_dict': scheduler.state_dict() if scheduler else None\n",
    "                    }, best_model_path)\n",
    "                    print(f\"Best model saved to {best_model_path} (Epoch {best_epoch}, Val Acc: {best_acc:.4f})\")\n",
    "        \n",
    "        if phase == 'train' and scheduler is not None and not isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "            scheduler.step()\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - start_time\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:.4f} at epoch {best_epoch}')\n",
    "    if best_acc > 0:\n",
    "        model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    final_model_path = os.path.join(save_dir, 'final_model.pth')\n",
    "    torch.save({\n",
    "        'epoch': num_epochs,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "        'loss': history['val_loss'][-1] if history['val_loss'] else (history['train_loss'][-1] if history['train_loss'] else 0.0),\n",
    "        'accuracy': history['val_acc'][-1] if history['val_acc'] else (history['train_acc'][-1] if history['train_acc'] else 0.0),\n",
    "    }, final_model_path)\n",
    "    print(f\"Final model saved to {final_model_path}\")\n",
    "    \n",
    "    if history['train_loss'] and history['val_loss']:\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.plot(history['train_loss'], label=\"Train Loss\")\n",
    "        plt.plot(history['val_loss'], label=\"Validation Loss\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Training and Validation Loss Over Epochs\")\n",
    "        plt.show()\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "def load_model(model, optimizer, checkpoint_path, scheduler=None):\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        print(f\"Checkpoint path {checkpoint_path} does not exist. Returning initial model.\")\n",
    "        return model, optimizer, scheduler, 0, 0.0, 0.0\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    if optimizer is not None and 'optimizer_state_dict' in checkpoint:\n",
    "        try:\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        except ValueError as e:\n",
    "            print(f\"Warning: Could not load optimizer state: {e}. Optimizer will be reinitialized.\")\n",
    "    if scheduler is not None and 'scheduler_state_dict' in checkpoint and checkpoint['scheduler_state_dict'] is not None:\n",
    "        try:\n",
    "            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not load scheduler state: {e}. Scheduler may be reinitialized or use default state.\")\n",
    "    start_epoch = checkpoint.get('epoch', 0)\n",
    "    loss = checkpoint.get('loss', 0.0)\n",
    "    accuracy = checkpoint.get('accuracy', 0.0)\n",
    "    print(f\"Model loaded from {checkpoint_path}. Epoch: {start_epoch}, Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "    return model, optimizer, scheduler, start_epoch, loss, accuracy\n",
    "\n",
    "def test_model(model, test_loader, criterion=None):\n",
    "    if test_loader is None or len(test_loader.dataset) == 0:\n",
    "        print(\"Test loader is None or dataset is empty. Skipping testing.\")\n",
    "        return 0.0, 0.0\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total_samples = 0\n",
    "    if criterion is None:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            total_samples += inputs.size(0)\n",
    "    if total_samples == 0:\n",
    "        test_loss = 0.0\n",
    "        test_acc = 0.0\n",
    "    else:\n",
    "        test_loss = running_loss / total_samples\n",
    "        test_acc = running_corrects.double() / total_samples\n",
    "    print(f'Test Loss: {test_loss:.4f} Acc: {test_acc:.4f}')\n",
    "    return test_loss, test_acc.item()\n",
    "\n",
    "def freeze_layers(model, num_layers_to_freeze):\n",
    "    \"\"\"Freezes the first num_layers_to_freeze layers of the model's features.\"\"\"\n",
    "    if hasattr(model, 'features') and isinstance(model.features, nn.Sequential):\n",
    "        layer_idx = 0\n",
    "        for child in model.features.children():\n",
    "            if isinstance(child, (nn.Conv2d, nn.Linear, nn.BatchNorm2d)):\n",
    "                 if layer_idx < num_layers_to_freeze:\n",
    "                    for param in child.parameters():\n",
    "                        param.requires_grad = False\n",
    "                 layer_idx +=1\n",
    "        print(f\"Froze {min(num_layers_to_freeze, layer_idx)} layers in model.features.\")\n",
    "    else:\n",
    "        params = list(model.parameters())\n",
    "        actual_layers_to_freeze = min(num_layers_to_freeze, len(params))\n",
    "        for i, param in enumerate(params):\n",
    "            if i < actual_layers_to_freeze:\n",
    "                param.requires_grad = False\n",
    "        print(f\"Froze first {actual_layers_to_freeze} parameter groups (layers) of the model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training Experiments\n",
    "\n",
    "This section details the training process for different models.\n",
    "**Important**: Ensure `data_root_example` below points to the correct path of your dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the root directory for your dataset.\n",
    "# <<< USER: CHANGE THIS PATH to your dataset location >>>\n",
    "data_root_example = \"./datasets/handwritten-english/augmented_images/augmented_images1\" \n",
    "\n",
    "# Check if the data_root_example path exists. If not, print a warning.\n",
    "if not os.path.exists(data_root_example):\n",
    "    print(f\"\\nWARNING: The directory '{data_root_example}' does not exist. \\nPlease ensure your dataset is available at this path or update 'data_root_example'.\")\n",
    "    print(\"Training experiments will likely fail if the path is incorrect.\")\n",
    "else:\n",
    "    print(f\"Using dataset root: {data_root_example}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1. Experiment 1: Training `ImprovedLetterCNN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Experiment 1: Training ImprovedLetterCNN ---\")\n",
    "\n",
    "if os.path.exists(data_root_example):\n",
    "    save_dir_cnn = 'model_checkpoints/cnn'\n",
    "    if not os.path.exists(save_dir_cnn):\n",
    "        os.makedirs(save_dir_cnn)\n",
    "        print(f\"Created checkpoint directory: {save_dir_cnn}\")\n",
    "\n",
    "    print(f\"Initializing data pipeline for CNN experiment with data_root: {data_root_example}\")\n",
    "    cnn_pipeline = HandwritingDataPipeline(data_root=data_root_example, image_size=(64,64), batch_size=32, do_transform=True)\n",
    "    train_loader_cnn, val_loader_cnn, test_loader_cnn = cnn_pipeline.get_loaders()\n",
    "    num_classes_cnn = cnn_pipeline.num_classes\n",
    "    \n",
    "    if num_classes_cnn > 0 and len(train_loader_cnn.dataset) > 0:\n",
    "        print(f\"Number of classes for CNN: {num_classes_cnn}\")\n",
    "        print(f\"Train samples: {len(train_loader_cnn.dataset)}, Val samples: {len(val_loader_cnn.dataset)}, Test samples: {len(test_loader_cnn.dataset)}\")\n",
    "\n",
    "        model_cnn = ImprovedLetterCNN(num_classes_cnn).to(device)\n",
    "        criterion_cnn = nn.CrossEntropyLoss()\n",
    "        optimizer_cnn = optim.Adam(model_cnn.parameters(), lr=0.0005)\n",
    "        scheduler_cnn = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_cnn, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "        num_epochs_cnn_train = 20 \n",
    "        print(f\"Starting training for ImprovedLetterCNN for {num_epochs_cnn_train} epochs...\")\n",
    "        \n",
    "        trained_model_cnn, history_cnn = train_model(model_cnn, train_loader_cnn, val_loader_cnn, \n",
    "                                                   criterion_cnn, optimizer_cnn, scheduler_cnn, \n",
    "                                                   num_epochs=num_epochs_cnn_train, save_dir=save_dir_cnn)\n",
    "        \n",
    "        print(\"\\nTesting the final trained ImprovedLetterCNN model on the test set:\")\n",
    "        test_model(trained_model_cnn, test_loader_cnn, criterion_cnn)\n",
    "\n",
    "        print(\"\\nLoading the best saved ImprovedLetterCNN model and testing it on the test set:\")\n",
    "        best_model_cnn_instance = ImprovedLetterCNN(num_classes_cnn).to(device)\n",
    "        dummy_optimizer_cnn = optim.Adam(best_model_cnn_instance.parameters()) \n",
    "        best_cnn_model_loaded, _, _, _, _, _ = load_model(best_model_cnn_instance, \n",
    "                                                       dummy_optimizer_cnn, \n",
    "                                                       os.path.join(save_dir_cnn, 'best_model.pth'))\n",
    "        test_model(best_cnn_model_loaded, test_loader_cnn, criterion_cnn)\n",
    "        \n",
    "        # Optional: Display augmented images from the CNN training loader\n",
    "        print(\"\\nDisplaying a sample of augmented images from CNN training loader...\")\n",
    "        display_augmented_images(train_loader_cnn, num_images=3, num_augmentations=3)\n",
    "    else:\n",
    "        print(\"Skipping Experiment 1: CNN training, due to invalid number of classes or empty train loader.\")\n",
    "else:\n",
    "    print(\"Skipping Experiment 1: CNN training, as the data_root_example path is invalid or dataset not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2. Experiment 2: Training `VGG19HandwritingModel` (Transfer Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Experiment 2: Training VGG19HandwritingModel ---\")\n",
    "\n",
    "if os.path.exists(data_root_example):\n",
    "    save_dir_vgg = 'model_checkpoints/vgg'\n",
    "    if not os.path.exists(save_dir_vgg):\n",
    "        os.makedirs(save_dir_vgg)\n",
    "        print(f\"Created checkpoint directory: {save_dir_vgg}\")\n",
    "\n",
    "    print(f\"Initializing data pipeline for VGG experiment with data_root: {data_root_example}\")\n",
    "    vgg_pipeline = HandwritingDataPipeline(data_root=data_root_example, image_size=(64,64), batch_size=32, do_transform=True)\n",
    "    train_loader_vgg, val_loader_vgg, test_loader_vgg = vgg_pipeline.get_loaders()\n",
    "    num_classes_vgg = vgg_pipeline.num_classes\n",
    "    num_epochs_vgg = 20\n",
    "\n",
    "    if num_classes_vgg > 0 and len(train_loader_vgg.dataset) > 0:\n",
    "        print(f\"Number of classes for VGG: {num_classes_vgg}\")\n",
    "        print(f\"Train samples: {len(train_loader_vgg.dataset)}, Val samples: {len(val_loader_vgg.dataset)}, Test samples: {len(test_loader_vgg.dataset)}\")\n",
    "\n",
    "        use_pretrained_vgg = True \n",
    "        model_vgg = VGG19HandwritingModel(num_classes=num_classes_vgg, device=device, pretrained=use_pretrained_vgg).to(device)\n",
    "        print(f\"VGG19 Model initialized {'with pretrained ImageNet weights' if use_pretrained_vgg else 'from scratch'}.\")\n",
    "\n",
    "        criterion_vgg = nn.CrossEntropyLoss()\n",
    "\n",
    "        if use_pretrained_vgg:\n",
    "            optimizer_vgg = optim.Adam([\n",
    "                {'params': model_vgg.features.parameters(), 'lr': 1e-5},\n",
    "                {'params': model_vgg.classifier.parameters(), 'lr': 1e-4}\n",
    "            ], weight_decay=1e-4)\n",
    "            scheduler_vgg = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_vgg, T_max=num_epochs_vgg, eta_min=1e-6)\n",
    "            print(\"Optimizer set up for pretrained VGG model with differential learning rates.\")\n",
    "        else:\n",
    "            optimizer_vgg = optim.Adam(model_vgg.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "            scheduler_vgg = torch.optim.lr_scheduler.OneCycleLR(optimizer_vgg, max_lr=1e-3, epochs=num_epochs_vgg, steps_per_epoch=len(train_loader_vgg))\n",
    "            print(\"Optimizer set up for VGG model training from scratch.\")\n",
    "\n",
    "        print(f\"Starting training for VGG19HandwritingModel for {num_epochs_vgg} epochs...\")\n",
    "        trained_model_vgg, history_vgg = train_model(model_vgg, train_loader_vgg, val_loader_vgg, \n",
    "                                                   criterion_vgg, optimizer_vgg, scheduler_vgg, \n",
    "                                                   num_epochs=num_epochs_vgg, save_dir=save_dir_vgg)\n",
    "\n",
    "        print(\"\\nTesting the final trained VGG19 model on the test set:\")\n",
    "        test_model(trained_model_vgg, test_loader_vgg, criterion_vgg)\n",
    "\n",
    "        print(\"\\nLoading the best saved VGG19 model and testing it on the test set:\")\n",
    "        best_model_vgg_instance = VGG19HandwritingModel(num_classes=num_classes_vgg, device=device, pretrained=False).to(device)\n",
    "        dummy_optimizer_vgg = optim.Adam(best_model_vgg_instance.parameters())\n",
    "        best_vgg_model_loaded, _, _, _, _, _ = load_model(best_model_vgg_instance, \n",
    "                                                       dummy_optimizer_vgg, \n",
    "                                                       os.path.join(save_dir_vgg, 'best_model.pth'))\n",
    "        test_model(best_vgg_model_loaded, test_loader_vgg, criterion_vgg)\n",
    "    else:\n",
    "        print(\"Skipping Experiment 2: VGG training, due to invalid number of classes or empty train loader.\")\n",
    "else:\n",
    "    print(\"Skipping Experiment 2: VGG training, as the data_root_example path is invalid or dataset not found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
